# Samsung Taylor FAB1 Performance Analysis

## Project Context

**Client:** Samsung (via SECAI - Samsung Engineering and Construction America Inc.)
**Analyst:** MXI (Construction Claims Consultants)
**Project:** Taylor FAB1 Semiconductor Fabrication Facility, Taylor, Texas

### Entities & Roles

| Entity | Role |
|--------|------|
| **Samsung** | Owner - semiconductor fab facility |
| **SECAI** | Samsung's US construction arm, MXI's direct client |
| **Yates Construction** | General Contractor (GC) |
| **Subcontractors** | ~50+ trade contractors (Berg Electric, Performance Contracting, etc.) |
| **MXI** | Claims consultant analyzing schedule delays and cost impacts |

### Our Service

MXI is analyzing the project to support SECAI in understanding:
1. **What caused schedule delays** - Which tasks, contractors, and issues drove critical path slippage
2. **Where quality issues occurred** - Location-based analysis of inspections, failures, and rework
3. **How labor was consumed** - Resource allocation patterns and productivity analysis
4. **Impact quantification** - Connecting delays to specific causes for claims support

---

## Approach

### Iterative Data Exploration

We follow an iterative cycle for each data source:

```
[Discover] → [Extract] → [Explore] → [Process] → [Integrate] → [Analyze]
     ↑                                                              |
     └──────────────────────────────────────────────────────────────┘
```

1. **Discover** - Identify available data sources (PDFs, Excel, APIs, web portals)
2. **Extract** - Download/scrape raw data, preserve original format
3. **Explore** - Understand structure, identify patterns, assess quality
4. **Process** - Parse, normalize, enrich with dimension IDs
5. **Integrate** - Link across sources via shared dimensions
6. **Analyze** - Answer business questions, iterate as new questions arise

### Tools & Techniques

| Tool | Use Case |
|------|----------|
| **Regex** | Pattern extraction (room codes, grid coordinates, dates) |
| **LLM Parsing** | Unstructured PDF extraction (Gemini for RABA/PSI quality reports) |
| **Embeddings** | Semantic search across narratives and documents (ChromaDB + Gemini) |
| **Pandas** | Data transformation, aggregation, joining |
| **Playwright** | Web scraping (RABA, PSI, ProjectSight portals) |
| **Pydantic** | Schema validation for output files |

### Processing Philosophy

- **Idempotent scripts** - Running twice produces same result, safe to re-run
- **Incremental where possible** - Skip already-processed files
- **Schema validation** - Validate outputs before overwriting (Power BI stability)
- **Traceable** - Raw files preserved, processing is reproducible

---

## Repository Organization

### Folder Structure

```
samsung-project/
├── CLAUDE.md                    # This file - high-level overview
├── scripts/
│   ├── {source}/                # One folder per data source
│   │   ├── CLAUDE.md            # Source-specific documentation
│   │   └── process/             # Processing scripts
│   ├── shared/                  # Cross-source utilities
│   │   ├── dimension_lookup.py  # Get dimension IDs
│   │   ├── daily_refresh.py     # Update all pipelines
│   │   └── ...
│   └── integrated_analysis/     # Cross-source integration
│       ├── location/            # Centralized location processing
│       ├── dimensions/          # Dimension table builders
│       └── ...
├── schemas/                     # Pydantic schemas for output validation
├── src/
│   ├── config/settings.py       # Path configuration
│   └── document_processor/      # LLM-based PDF extraction pipeline
└── tests/
```

### Self-Documenting Sources

Each `scripts/{source}/` folder contains:
- `CLAUDE.md` - Purpose, data flow, usage examples (≤150 lines)
- `process/` - Processing scripts
- `process/run.sh` - Pipeline orchestrator

**Current sources:** `primavera/`, `tbm/`, `projectsight/`, `raba/`, `psi/`, `narratives/`

### Data Directory (Separate from Repo)

Data lives in a local directory specified by `WINDOWS_DATA_DIR` in `.env`:

```
{WINDOWS_DATA_DIR}/
├── raw/{source}/           # Source files as received (100% traceable)
│   ├── primavera/          # XER schedule files
│   ├── tbm/                # Daily plan Excel files
│   ├── projectsight/       # Daily reports JSON, NCR exports
│   ├── raba/               # Quality inspection PDFs
│   ├── psi/                # Quality inspection PDFs
│   └── ...
└── processed/{source}/     # Output files generated by this repo
    ├── tbm/work_entries_enriched.csv
    ├── raba/raba_consolidated.csv
    ├── projectsight/labor_entries.csv
    └── integrated_analysis/dimensions/dim_*.csv
```

**Rules:**
- `raw/` is read-only, never modified by scripts
- `processed/` is generated output, can be regenerated from raw
- Git tracks code, not data (data is on OneDrive)

---

## Dimension Tables

Dimension tables enable joining across data sources. Located in `processed/integrated_analysis/dimensions/`.

### dim_location (Most Complex)

The location dimension bridges data sources through a **grid-based spatial model**.

#### The Problem

Different sources describe locations differently:
- P6 Schedule: Room codes (`FAB116406`)
- Quality Reports: Grid coordinates (`G/10-12`)
- TBM Daily Plans: Building + Level + Area (`FAB, 2F, G~K/8~15`)
- Labor Data: No location at all

#### The Solution: Grid Bounds

Every location has grid bounds (row min/max, col min/max):

```
Grid System (same across all buildings):
     1    5    10   15   20   25   30
  A  ┌────┬────┬────┬────┬────┬────┐
  B  │    │    │    │    │    │    │
  C  │    │ ┌──┴────┴──┐ │    │    │   ← Room FAB116406
  D  │    │ │          │ │    │    │     grid: C-E / 8-12
  E  │    │ └──┬────┬──┘ │    │    │
  F  │    │    │    │    │    │    │
     └────┴────┴────┴────┴────┴────┘
```

**Key insight:** Grid coordinates are consistent across buildings (FAB, SUE, SUW, FIZ) and levels. A quality inspection at "G/10" on Level 2 can be matched to rooms on that level whose grid bounds contain G/10.

#### Location Hierarchy

| Type | Example | Grid Coverage |
|------|---------|---------------|
| ROOM | FAB116406 | Specific bounds (C-E/8-12) |
| STAIR | STR-21 | Point or small area |
| ELEVATOR | ELV-01 | Point (single grid cell) |
| GRIDLINE | G/10 | Point or range |
| LEVEL | FAB-2F | Entire level |
| BUILDING | FAB | Entire building |

#### Centralized Location Processing

**CRITICAL:** All location enrichment MUST use the centralized module:

```python
from scripts.integrated_analysis.location import enrich_location

result = enrich_location(
    building='FAB',
    level='2F',
    grid='G/10-12',
    source='RABA'
)

# Returns:
result.dim_location_id      # FK to dim_location
result.location_type        # ROOM, GRIDLINE, LEVEL, etc.
result.affected_rooms       # JSON array of rooms in grid bounds
result.affected_rooms_count # Number of rooms matched
```

See `scripts/integrated_analysis/location/CLAUDE.md` for full documentation.

### dim_company

Normalizes company names across sources (each source uses different spellings/abbreviations).

| Field | Description |
|-------|-------------|
| company_id | Primary key |
| canonical_name | Standardized name |
| primary_trade_id | FK to dim_trade |

**Aliases:** `map_company_aliases.csv` maps variants → canonical name
- "Berg Electric" → "Berg"
- "BERG ELEC" → "Berg"
- "Berg Electrical" → "Berg"

### dim_csi_section

CSI (Construction Specifications Institute) codes classify work types:

| Field | Description |
|-------|-------------|
| csi_section_id | Primary key |
| csi_code | Code like "03 30 00" |
| csi_title | "Cast-in-Place Concrete" |

CSI is inferred from:
1. Activity descriptions (keywords like "drywall", "concrete")
2. Company's primary trade
3. Division codes from source data

### dim_trade

High-level trade categories (CONCRETE, STEEL, DRYWALL, MEP, etc.)

---

## Data Sources

### Power BI Fact Tables

| Source | File | Records | Location | Company | CSI |
|--------|------|---------|----------|---------|-----|
| TBM | `tbm/work_entries_enriched.csv` | 76K | 22% | 96% | 81% |
| RABA | `raba/raba_consolidated.csv` | 9.4K | 100% | 89% | 100% |
| PSI | `psi/psi_consolidated.csv` | 6.3K | 100% | 99% | 99% |
| ProjectSight | `projectsight/labor_entries.csv` | 863K | 0%* | 100% | 100% |
| NCR | `projectsight/ncr_consolidated.csv` | 2K | N/A | 66% | 91% |

*ProjectSight labor data has no location in source

### Source Descriptions

| Source | Purpose | Raw Location |
|--------|---------|--------------|
| **Primavera P6** | Schedule snapshots (66 XER files) | `raw/primavera/` |
| **TBM** | Daily work plans from toolbox meetings | `raw/tbm/` |
| **ProjectSight** | Labor hours from daily reports | `raw/projectsight/` |
| **RABA** | Quality inspections (RKCI system) | `raw/raba/` |
| **PSI** | Quality inspections (Const Hive) | `raw/psi/` |
| **NCR** | Non-conformance records | `raw/projectsight/` |
| **Narratives** | Schedule narratives, weekly reports | `raw/narratives/` |

### Embeddings-Only Sources

Some sources are consumed via semantic search rather than structured tables:
- **Weekly Reports** - Narratives and issues searchable via embeddings
- **Schedule Narratives** - P6 narrative exports

```bash
python -m scripts.narratives.embeddings search "HVAC delays"
```

---

## Daily Operations

### Refresh All Data

Single command to update all Power BI data sources:

```bash
python -m scripts.shared.daily_refresh
python -m scripts.shared.daily_refresh --dry-run      # Preview only
python -m scripts.shared.daily_refresh --skip-scrapers # Fast local refresh
```

This runs (in order):
1. **Parsers** - TBM, P6, ProjectSight (incremental)
2. **Scrapers** - RABA, PSI (manifest-tracked)
3. **Dimensions** - Build dim_location
4. **Consolidation** - Enrich all fact tables with dimension IDs

### Environment Setup

Create `.env` in project root:

```bash
WINDOWS_DATA_DIR=/path/to/data/directory

# Scraper credentials
RABA_USERNAME=...
RABA_PASSWORD=...
PSI_BASE_URL=...
PSI_USERNAME=...
PSI_PASSWORD=...
PROJECTSIGHT_USERNAME=...
PROJECTSIGHT_PASSWORD=...
```

### Schema Validation

Output files are validated against Pydantic schemas before writing:

```python
from schemas.validator import validated_df_to_csv

validated_df_to_csv(df, output_path)  # Raises if schema mismatch
```

**Critical rule:** Never remove or rename columns in `processed/` files - Power BI depends on them.

Run schema tests:
```bash
pytest tests/unit/test_schemas.py -v
```

---

## Navigation

| Topic | Location |
|-------|----------|
| Location processing | `scripts/integrated_analysis/location/CLAUDE.md` |
| TBM pipeline | `scripts/tbm/CLAUDE.md` |
| ProjectSight pipeline | `scripts/projectsight/CLAUDE.md` |
| RABA pipeline | `scripts/raba/CLAUDE.md` |
| PSI pipeline | `scripts/psi/CLAUDE.md` |
| Embeddings search | `scripts/narratives/CLAUDE.md` |
| Document processor | `src/document_processor/CLAUDE.md` |
| Schedule slippage | `scripts/integrated_analysis/CLAUDE.md` |
| Shared utilities | `scripts/shared/CLAUDE.md` |

### Key Scripts

| Script | Purpose |
|--------|---------|
| `scripts/shared/daily_refresh.py` | Update all pipelines |
| `scripts/shared/dimension_lookup.py` | Get dimension IDs |
| `scripts/integrated_analysis/location/` | Centralized location enrichment |
| `scripts/integrated_analysis/dimensions/build_dim_location.py` | Build location dimension |
