{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProjectSight File Downloader\n",
    "\n",
    "This notebook demonstrates how to use **Playwright** to:\n",
    "1. Authenticate with a web application\n",
    "2. Apply filters to narrow down results\n",
    "3. Extract full submittal data from virtualized grids\n",
    "4. Download all attached files\n",
    "5. Maintain an idempotent manifest (safe to re-run)\n",
    "\n",
    "## Playwright Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| `Page` | A browser tab - your main interaction point |\n",
    "| `Frame` | An iframe within a page (ProjectSight uses these) |\n",
    "| `Locator` | A way to find elements - preferred over raw selectors |\n",
    "| `evaluate()` | Run JavaScript in the browser context |\n",
    "| `wait_for_*` | Wait for conditions before proceeding |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: pcuriel@mxi.pro\n",
      "Filter: 05 12 00 - Structural Steel\n",
      "Output directory: /mnt/c/Users/pdcur/OneDrive - MXI/Samsung - Samsung/Dashboard/Data/raw/projectsight/submittals/05_12_00\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "from playwright.async_api import async_playwright, Page, Frame, Locator\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(Path('/home/pdcur/samsung-project/.env'))\n",
    "\n",
    "\n",
    "def windows_to_wsl_path(windows_path: str) -> Path:\n",
    "    \"\"\"\n",
    "    Convert Windows path to WSL2 path.\n",
    "\n",
    "    Examples:\n",
    "        C:\\\\Users\\\\name\\\\folder -> /mnt/c/Users/name/folder\n",
    "        D:\\\\Data -> /mnt/d/Data\n",
    "    \"\"\"\n",
    "    if not windows_path:\n",
    "        return Path('.')\n",
    "\n",
    "    # Already a Unix path? Return as-is\n",
    "    if windows_path.startswith('/'):\n",
    "        return Path(windows_path)\n",
    "\n",
    "    # Convert backslashes to forward slashes\n",
    "    path = windows_path.replace('\\\\', '/')\n",
    "\n",
    "    # Match drive letter pattern (C:/ or C:)\n",
    "    match = re.match(r'^([A-Za-z]):[/]?(.*)$', path)\n",
    "    if match:\n",
    "        drive = match.group(1).lower()\n",
    "        rest = match.group(2)\n",
    "        return Path(f'/mnt/{drive}/{rest}')\n",
    "\n",
    "    return Path(windows_path)\n",
    "\n",
    "\n",
    "# Configuration\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Central configuration for the scraper.\"\"\"\n",
    "    username: str = os.getenv('PROJECTSIGHT_USERNAME_2', '')\n",
    "    password: str = os.getenv('PROJECTSIGHT_PASSWORD_2', '')\n",
    "    org_id: str = '4540f425-f7b5-4ad8-837d-c270d5d09490'\n",
    "    project_id: int = 3\n",
    "\n",
    "    # Filter settings\n",
    "    spec_section_filter: str = '05 12 00 - Structural Steel'  # CSI code to filter by\n",
    "\n",
    "    # Paths\n",
    "    session_path: Path = Path.home() / '.projectsight_session.json'\n",
    "    base_url: str = 'https://prod.projectsightapp.trimble.com'\n",
    "\n",
    "    # Output paths - includes filter in folder name for organization\n",
    "    output_dir: Path = field(init=False)\n",
    "    manifest_path: Path = field(init=False)\n",
    "    submittals_csv_path: Path = field(init=False)\n",
    "    downloads_dir: Path = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # Create filter-specific output directory\n",
    "        filter_slug = self.spec_section_filter.split(' - ')[0].replace(' ', '_')  # e.g., \"05_12_00\"\n",
    "        # Convert Windows path to WSL path\n",
    "        data_dir = windows_to_wsl_path(os.getenv('WINDOWS_DATA_DIR', ''))\n",
    "        base_output = data_dir / 'raw' / 'projectsight' / 'submittals'\n",
    "        self.output_dir = base_output / filter_slug\n",
    "        self.manifest_path = self.output_dir / 'manifest.json'\n",
    "        self.submittals_csv_path = self.output_dir / 'submittals.csv'\n",
    "        self.downloads_dir = self.output_dir / 'files'\n",
    "\n",
    "    @property\n",
    "    def submittals_url(self) -> str:\n",
    "        return f\"{self.base_url}/web/app/Project?listid=-4045&orgid={self.org_id}&projid={self.project_id}\"\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Ensure output directories exist\n",
    "config.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "config.downloads_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Username: {config.username}\")\n",
    "print(f\"Filter: {config.spec_section_filter}\")\n",
    "print(f\"Output directory: {config.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Manifest System (Idempotency)\n",
    "\n",
    "The manifest tracks:\n",
    "- **Processed submittals**: Which rows we've already scanned for attachments\n",
    "- **Downloaded files**: Which files we've already downloaded (by FileID)\n",
    "- **Filter applied**: What filter was used (for verification)\n",
    "\n",
    "This allows safe re-runs - we skip already-processed items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest loaded:\n",
      "  - Filter: 05 12 00 - Structural Steel\n",
      "  - Processed submittals: 276\n",
      "  - Known attachments: 947\n",
      "  - Downloaded files: 20\n",
      "  - Pending downloads: 927\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Manifest:\n",
    "    \"\"\"\n",
    "    Tracks processing state for idempotent runs.\n",
    "    \"\"\"\n",
    "    filter_applied: str = ''  # Track which filter was used\n",
    "    processed_submittals: set = field(default_factory=set)\n",
    "    downloaded_files: dict = field(default_factory=dict)\n",
    "    attachments: list = field(default_factory=list)\n",
    "    last_updated: str = ''\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path: Path) -> 'Manifest':\n",
    "        \"\"\"Load manifest from disk, or create empty one.\"\"\"\n",
    "        if path.exists():\n",
    "            data = json.loads(path.read_text())\n",
    "            return cls(\n",
    "                filter_applied=data.get('filter_applied', ''),\n",
    "                processed_submittals=set(data.get('processed_submittals', [])),\n",
    "                downloaded_files=data.get('downloaded_files', {}),\n",
    "                attachments=data.get('attachments', []),\n",
    "                last_updated=data.get('last_updated', '')\n",
    "            )\n",
    "        return cls()\n",
    "    \n",
    "    def save(self, path: Path) -> None:\n",
    "        \"\"\"Save manifest to disk.\"\"\"\n",
    "        self.last_updated = datetime.now().isoformat()\n",
    "        data = {\n",
    "            'filter_applied': self.filter_applied,\n",
    "            'processed_submittals': list(self.processed_submittals),\n",
    "            'downloaded_files': self.downloaded_files,\n",
    "            'attachments': self.attachments,\n",
    "            'last_updated': self.last_updated\n",
    "        }\n",
    "        path.write_text(json.dumps(data, indent=2))\n",
    "    \n",
    "    def is_submittal_processed(self, submittal_id: int) -> bool:\n",
    "        return submittal_id in self.processed_submittals\n",
    "    \n",
    "    def mark_submittal_processed(self, submittal_id: int) -> None:\n",
    "        self.processed_submittals.add(submittal_id)\n",
    "    \n",
    "    def is_file_downloaded(self, file_id: str) -> bool:\n",
    "        return file_id in self.downloaded_files\n",
    "    \n",
    "    def mark_file_downloaded(self, file_id: str, metadata: dict) -> None:\n",
    "        self.downloaded_files[file_id] = {\n",
    "            **metadata,\n",
    "            'downloaded_at': datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    def add_attachment(self, attachment: dict) -> None:\n",
    "        \"\"\"Add attachment if not already tracked.\"\"\"\n",
    "        if not any(a['file_id'] == attachment['file_id'] for a in self.attachments):\n",
    "            self.attachments.append(attachment)\n",
    "    \n",
    "    def get_pending_downloads(self) -> list[dict]:\n",
    "        \"\"\"Get attachments that haven't been downloaded yet.\"\"\"\n",
    "        return [a for a in self.attachments if not self.is_file_downloaded(a['file_id'])]\n",
    "    \n",
    "    def reset_downloads(self) -> None:\n",
    "        \"\"\"Reset download tracking only - keeps processed submittals and attachments.\"\"\"\n",
    "        self.downloaded_files = {}\n",
    "        print(f\"Reset downloads. {len(self.attachments)} attachments now pending.\")\n",
    "\n",
    "\n",
    "# Load or create manifest\n",
    "manifest = Manifest.load(config.manifest_path)\n",
    "print(f\"Manifest loaded:\")\n",
    "print(f\"  - Filter: {manifest.filter_applied or '(none)'}\")\n",
    "print(f\"  - Processed submittals: {len(manifest.processed_submittals)}\")\n",
    "print(f\"  - Known attachments: {len(manifest.attachments)}\")\n",
    "print(f\"  - Downloaded files: {len(manifest.downloaded_files)}\")\n",
    "print(f\"  - Pending downloads: {len(manifest.get_pending_downloads())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Browser & Authentication Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def launch_browser(headless: bool = False) -> tuple:\n",
    "    \"\"\"\n",
    "    Launch browser with optional saved session.\n",
    "    \n",
    "    Returns: (playwright, browser, context, page)\n",
    "    \"\"\"\n",
    "    pw = await async_playwright().start()\n",
    "    browser = await pw.chromium.launch(headless=headless)\n",
    "    \n",
    "    context_options = {\"viewport\": {\"width\": 1920, \"height\": 1080}}\n",
    "    if config.session_path.exists():\n",
    "        context_options[\"storage_state\"] = str(config.session_path)\n",
    "        print(\"Loading saved session...\")\n",
    "    \n",
    "    context = await browser.new_context(**context_options)\n",
    "    page = await context.new_page()\n",
    "    \n",
    "    return pw, browser, context, page\n",
    "\n",
    "\n",
    "async def login_if_needed(page: Page, context) -> bool:\n",
    "    \"\"\"\n",
    "    Navigate to ProjectSight and login if session expired.\n",
    "    Returns True if login was performed.\n",
    "    \"\"\"\n",
    "    await page.goto(config.submittals_url, wait_until='domcontentloaded')\n",
    "    await page.wait_for_timeout(2000)\n",
    "    \n",
    "    needs_login = 'id.trimble.com' in page.url or 'sign_in' in page.url\n",
    "    \n",
    "    if not needs_login:\n",
    "        print(\"Already authenticated!\")\n",
    "        return False\n",
    "    \n",
    "    print(\"Login required...\")\n",
    "    \n",
    "    # Dismiss cookie banner\n",
    "    try:\n",
    "        await page.get_by_role('button', name='Reject All').click(timeout=3000)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Username\n",
    "    await page.fill('#username-field', config.username)\n",
    "    await page.keyboard.press('Tab')\n",
    "    await page.get_by_role('button', name='Next').click()\n",
    "    \n",
    "    # Password\n",
    "    await page.wait_for_selector('input[name=\"password\"]', timeout=5000)\n",
    "    await page.fill('input[name=\"password\"]', config.password)\n",
    "    await page.keyboard.press('Tab')\n",
    "    await page.get_by_role('button', name='Sign in').click()\n",
    "    \n",
    "    await page.wait_for_url('**projectsight**', timeout=15000)\n",
    "    print(f\"Logged in!\")\n",
    "    \n",
    "    await context.storage_state(path=str(config.session_path))\n",
    "    return True\n",
    "\n",
    "\n",
    "async def get_content_frame(page: Page) -> Frame:\n",
    "    \"\"\"Get the iframe containing the main content.\"\"\"\n",
    "    frame = page.frame(name='fraMenuContent')\n",
    "    if not frame:\n",
    "        raise RuntimeError(\"Content frame not found\")\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filter Functions\n",
    "\n",
    "### Applying Spec Section Filter\n",
    "The Submittals page has a search panel with filters. We need to:\n",
    "1. Open the Spec Section dropdown\n",
    "2. Navigate to the correct CSI division (e.g., \"05 - Metals\")\n",
    "3. Select the specific section (e.g., \"05 12 00 - Structural Steel\")\n",
    "\n",
    "**Playwright Tip:** Use `Locator` objects for robust element finding. They auto-wait and retry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def apply_spec_section_filter(page: Page, frame: Frame, spec_section: str) -> None:\n",
    "    \"\"\"\n",
    "    Apply a Spec Section (CSI code) filter to the submittals grid.\n",
    "    \n",
    "    Args:\n",
    "        page: The Page object (needed for frame locator)\n",
    "        frame: The content frame\n",
    "        spec_section: The CSI code to filter by (e.g., \"05 12 00 - Structural Steel\")\n",
    "    \n",
    "    Playwright Tips:\n",
    "        - `page.locator().content_frame` gets a FrameLocator for iframe content\n",
    "        - `get_by_role()` finds elements by accessibility role (more robust)\n",
    "        - `get_by_title()` finds elements by their title attribute\n",
    "    \"\"\"\n",
    "    print(f\"Applying filter: {spec_section}\")\n",
    "    \n",
    "    # Get frame locator for cleaner syntax\n",
    "    frame_locator = page.locator('iframe[name=\"fraMenuContent\"]').content_frame\n",
    "    \n",
    "    # 1. Click the Spec Section input to open the dropdown\n",
    "    spec_input = frame_locator.locator('#ucSearchPanel_ctl38_txtCSICodeLookupInput')\n",
    "    await spec_input.click(timeout=5000)\n",
    "    await page.wait_for_timeout(500)\n",
    "    \n",
    "    # 2. Parse the CSI code to get the division (first 2 digits)\n",
    "    # e.g., \"05 12 00\" -> division \"05\" (Metals)\n",
    "    csi_code = spec_section.split(' - ')[0]  # \"05 12 00\"\n",
    "    division = csi_code.split()[0]  # \"05\"\n",
    "    \n",
    "    # CSI Division codes map to container IDs\n",
    "    # Division 05 (Metals) -> container ID 73003\n",
    "    division_container_ids = {\n",
    "        '03': '73001',  # Concrete\n",
    "        '05': '73003',  # Metals\n",
    "        '07': '73005',  # Thermal & Moisture Protection\n",
    "        '09': '73007',  # Finishes\n",
    "        '22': '73018',  # Plumbing\n",
    "        '23': '73019',  # HVAC\n",
    "        '26': '73022',  # Electrical\n",
    "        # Add more as needed\n",
    "    }\n",
    "    \n",
    "    container_id = division_container_ids.get(division)\n",
    "    if container_id:\n",
    "        # Try to expand the division if not already expanded\n",
    "        try:\n",
    "            expand_btn = frame_locator.locator(f'#ucSearchPanel_ctl38_CSICodePopupTreeContainer_{container_id}').get_by_title('Expand Row')\n",
    "            await expand_btn.click(timeout=2000)\n",
    "            print(f\"Expanded division {division}\")\n",
    "        except:\n",
    "            print(f\"Division {division} already expanded or not found\")\n",
    "    \n",
    "    await page.wait_for_timeout(500)\n",
    "    \n",
    "    # 3. Click on the specific spec section\n",
    "    await frame_locator.get_by_role('gridcell', name=spec_section).click(timeout=5000)\n",
    "    print(f\"Selected: {spec_section}\")\n",
    "    \n",
    "    # 4. Wait for filter to apply and switch to list view\n",
    "    await page.wait_for_timeout(1000)\n",
    "    \n",
    "    # Switch to list view for easier parsing\n",
    "    await frame_locator.locator('#imgSwitchToListView').click(timeout=2000)\n",
    "    print(\"Switched to list view\")\n",
    "    \n",
    "    # Wait for grid to reload with filtered data\n",
    "    await page.wait_for_timeout(2000)\n",
    "\n",
    "\n",
    "async def get_current_filter_count(frame: Frame) -> int:\n",
    "    \"\"\"\n",
    "    Get the number of records currently shown (after filter).\n",
    "    \"\"\"\n",
    "    return await frame.evaluate('''\n",
    "        () => {\n",
    "            const grid = $(\"#ugDataView\").data(\"igGrid\");\n",
    "            return grid ? grid.dataSource.data().length : 0;\n",
    "        }\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_all_submittals_full(frame: Frame) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Get ALL submittal data with ALL fields from the grid.\n",
    "    \n",
    "    NOTE: This returns whatever is currently in the grid.\n",
    "    If a filter is applied, only filtered records are returned.\n",
    "    \"\"\"\n",
    "    return await frame.evaluate('''\n",
    "        () => {\n",
    "            const grid = $(\"#ugDataView\").data(\"igGrid\");\n",
    "            if (!grid) throw new Error(\"Grid not found\");\n",
    "            \n",
    "            return grid.dataSource.data().map(row => {\n",
    "                const clean = {};\n",
    "                for (const [key, value] of Object.entries(row)) {\n",
    "                    if (key.startsWith('$') || key.startsWith('_')) continue;\n",
    "                    if (typeof value === 'function') continue;\n",
    "                    clean[key] = value;\n",
    "                }\n",
    "                return clean;\n",
    "            });\n",
    "        }\n",
    "    ''')\n",
    "\n",
    "\n",
    "async def scroll_to_row(frame: Frame, row_index: int) -> None:\n",
    "    \"\"\"Scroll the virtualized grid to show a specific row.\"\"\"\n",
    "    await frame.evaluate('(idx) => $(\"#ugDataView\").data(\"igGrid\").virtualScrollTo(idx)', row_index)\n",
    "\n",
    "\n",
    "async def dismiss_modal_if_present(page: Page) -> bool:\n",
    "    \"\"\"\n",
    "    Dismiss any modal overlay that might be blocking clicks.\n",
    "    Returns True if a modal was dismissed.\n",
    "    \"\"\"\n",
    "    frame = page.frame(name='fraMenuContent')\n",
    "    if not frame:\n",
    "        return False\n",
    "    \n",
    "    dismissed = await frame.evaluate('''\n",
    "        () => {\n",
    "            // Try to find and hide modal overlays\n",
    "            const modals = document.querySelectorAll('.modalBackgroundDiv, .modal-backdrop, [class*=\"modal\"]');\n",
    "            let dismissed = false;\n",
    "            for (const modal of modals) {\n",
    "                if (modal.style.display !== 'none') {\n",
    "                    modal.style.display = 'none';\n",
    "                    dismissed = true;\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            // Also try clicking any close buttons\n",
    "            const closeButtons = document.querySelectorAll('.modal-close, .close-modal, [class*=\"close\"]');\n",
    "            for (const btn of closeButtons) {\n",
    "                try { btn.click(); dismissed = true; } catch(e) {}\n",
    "            }\n",
    "            \n",
    "            // Press Escape to close any modal\n",
    "            document.dispatchEvent(new KeyboardEvent('keydown', { key: 'Escape', keyCode: 27 }));\n",
    "            \n",
    "            return dismissed;\n",
    "        }\n",
    "    ''')\n",
    "    \n",
    "    if dismissed:\n",
    "        await page.wait_for_timeout(300)\n",
    "    \n",
    "    return dismissed\n",
    "\n",
    "\n",
    "async def click_row_and_wait_for_sidebar(page: Page, submittal_id: int, timeout_ms: int = 5000, initial_delay_ms: int = 1000) -> bool:\n",
    "    \"\"\"\n",
    "    Click a row using Playwright's native click (not JavaScript .click()).\n",
    "    This properly triggers Angular's event handlers.\n",
    "    \n",
    "    Args:\n",
    "        page: Playwright page object\n",
    "        submittal_id: The submittal ID to click\n",
    "        timeout_ms: Max time to wait for sidebar to load\n",
    "        initial_delay_ms: Time to wait after click before checking sidebar (default 1 second)\n",
    "    \n",
    "    Returns True if sidebar loaded successfully.\n",
    "    \"\"\"\n",
    "    # First, dismiss any modal that might be blocking\n",
    "    await dismiss_modal_if_present(page)\n",
    "    \n",
    "    # Use Playwright's locator to click - this simulates a real user click\n",
    "    frame_locator = page.locator('iframe[name=\"fraMenuContent\"]').content_frame\n",
    "    row_locator = frame_locator.locator(f'tr[data-id=\"{submittal_id}\"]')\n",
    "    \n",
    "    try:\n",
    "        # Try normal click first\n",
    "        await row_locator.click(timeout=2000)\n",
    "    except Exception as e:\n",
    "        # If blocked by modal, try to dismiss and retry\n",
    "        await dismiss_modal_if_present(page)\n",
    "        await page.wait_for_timeout(500)\n",
    "        \n",
    "        try:\n",
    "            # Retry with force click (bypasses actionability checks)\n",
    "            await row_locator.click(timeout=2000, force=True)\n",
    "        except Exception as e2:\n",
    "            # Last resort: use JavaScript click\n",
    "            frame = page.frame(name='fraMenuContent')\n",
    "            clicked = await frame.evaluate('''\n",
    "                (id) => {\n",
    "                    const row = document.querySelector(`tr[data-id=\"${id}\"]`);\n",
    "                    if (row) { row.click(); return true; }\n",
    "                    return false;\n",
    "                }\n",
    "            ''', submittal_id)\n",
    "            if not clicked:\n",
    "                return False\n",
    "    \n",
    "    # Wait for sidebar to start loading before polling\n",
    "    await page.wait_for_timeout(initial_delay_ms)\n",
    "    \n",
    "    # Wait for sidebar to load by polling for .singleLinkedItem elements\n",
    "    frame = page.frame(name='fraMenuContent')\n",
    "    poll_interval = 300  # Increased from 200ms\n",
    "    max_polls = timeout_ms // poll_interval\n",
    "    \n",
    "    for _ in range(max_polls):\n",
    "        # Check if attachments have loaded or sidebar is ready\n",
    "        sidebar_ready = await frame.evaluate('''\n",
    "            () => {\n",
    "                // Check for attachment items\n",
    "                const items = document.querySelectorAll('.singleLinkedItem');\n",
    "                if (items.length > 0) return 'has_attachments';\n",
    "                \n",
    "                // Check if detail panel exists and has content\n",
    "                const panel = document.querySelector('.detailPanelInner, .rightPanelItem');\n",
    "                if (panel && panel.children.length > 2) return 'panel_loaded';\n",
    "                \n",
    "                return false;\n",
    "            }\n",
    "        ''')\n",
    "        \n",
    "        if sidebar_ready:\n",
    "            # Give Angular a moment to finish rendering\n",
    "            await page.wait_for_timeout(300)\n",
    "            return True\n",
    "        \n",
    "        await page.wait_for_timeout(poll_interval)\n",
    "    \n",
    "    # Timeout - return True anyway to try extraction\n",
    "    return True\n",
    "\n",
    "\n",
    "# Alias for compatibility\n",
    "async def click_row(frame: Frame, submittal_id: int, page: Page) -> bool:\n",
    "    \"\"\"Click a row to load its details sidebar. Returns True if successful.\"\"\"\n",
    "    return await click_row_and_wait_for_sidebar(page, submittal_id)\n",
    "\n",
    "\n",
    "async def extract_attachments(frame: Frame, submittal_id: int, submittal_number: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Extract all file attachments from the currently loaded sidebar.\n",
    "    \n",
    "    The sidebar uses Angular and attachments are in elements with class 'singleLinkedItem'.\n",
    "    We access the Angular scope to get file metadata.\n",
    "    \"\"\"\n",
    "    raw = await frame.evaluate('''\n",
    "        () => {\n",
    "            // Try multiple selectors - the UI might use different classes\n",
    "            let items = document.querySelectorAll('.singleLinkedItem');\n",
    "            \n",
    "            // If no items found, try alternative selectors\n",
    "            if (items.length === 0) {\n",
    "                items = document.querySelectorAll('[ng-repeat*=\"attachment\"]');\n",
    "            }\n",
    "            if (items.length === 0) {\n",
    "                items = document.querySelectorAll('.linked-item, .attachment-item, .file-item');\n",
    "            }\n",
    "            \n",
    "            const results = [];\n",
    "            const seen = new Set();\n",
    "            \n",
    "            for (const item of items) {\n",
    "                try {\n",
    "                    // Try to get Angular scope\n",
    "                    const scope = angular.element(item).scope();\n",
    "                    \n",
    "                    // The attachment might be in different scope properties\n",
    "                    const att = scope?.attachment || scope?.file || scope?.item;\n",
    "                    if (!att) continue;\n",
    "                    \n",
    "                    // FileID might be named differently\n",
    "                    const fileId = att.FileID || att.fileId || att.Id || att.id;\n",
    "                    if (!fileId || seen.has(fileId)) continue;\n",
    "                    seen.add(fileId);\n",
    "                    \n",
    "                    // Find field label by looking at parent context\n",
    "                    let fieldLabel = null;\n",
    "                    let current = item;\n",
    "                    while (current && !fieldLabel) {\n",
    "                        let sibling = current.previousElementSibling;\n",
    "                        while (sibling) {\n",
    "                            const text = sibling.textContent?.trim();\n",
    "                            if (text === 'Description' || text === 'Approved docs') {\n",
    "                                fieldLabel = text;\n",
    "                                break;\n",
    "                            }\n",
    "                            sibling = sibling.previousElementSibling;\n",
    "                        }\n",
    "                        current = current.parentElement;\n",
    "                    }\n",
    "                    \n",
    "                    results.push({\n",
    "                        file_id: fileId,\n",
    "                        file_name: att.FileName || att.fileName || att.Name || att.name || 'unknown',\n",
    "                        file_size: att.FileSize || att.fileSize || att.Size || 0,\n",
    "                        file_type: att.FileType || att.fileType || att.Type || 'unknown',\n",
    "                        field_label: fieldLabel || 'unknown'\n",
    "                    });\n",
    "                } catch(e) {\n",
    "                    // Silently continue on error\n",
    "                }\n",
    "            }\n",
    "            return results;\n",
    "        }\n",
    "    ''')\n",
    "    \n",
    "    for att in raw:\n",
    "        att['submittal_id'] = submittal_id\n",
    "        att['submittal_number'] = submittal_number\n",
    "    \n",
    "    return raw\n",
    "\n",
    "\n",
    "async def debug_sidebar(frame: Frame, page: Page) -> dict:\n",
    "    \"\"\"\n",
    "    Debug helper to inspect what's in the sidebar after clicking a row.\n",
    "    Checks BOTH the iframe and the main page.\n",
    "    \"\"\"\n",
    "    # Check in iframe (frame)\n",
    "    frame_debug = await frame.evaluate('''\n",
    "        () => {\n",
    "            const debug = {\n",
    "                location: 'iframe',\n",
    "                singleLinkedItems: document.querySelectorAll('.singleLinkedItem').length,\n",
    "                ngRepeatAttachment: document.querySelectorAll('[ng-repeat*=\"attachment\"]').length,\n",
    "                detailPanelExists: !!document.querySelector('.detailPanelInner, .detail-panel'),\n",
    "                rightPanelItems: document.querySelectorAll('.rightPanelItem').length,\n",
    "                modalVisible: !!document.querySelector('.modalBackgroundDiv[style*=\"block\"], .modalBackgroundDiv:not([style*=\"none\"])'),\n",
    "            };\n",
    "            \n",
    "            // Get the detail panel HTML snippet for inspection\n",
    "            const panel = document.querySelector('.detailPanelInner, .rightPanelItem');\n",
    "            if (panel) {\n",
    "                debug.panelChildCount = panel.children.length;\n",
    "                debug.panelTextSnippet = panel.textContent?.substring(0, 300);\n",
    "            }\n",
    "            \n",
    "            // Get relevant classes\n",
    "            const allElements = document.querySelectorAll('*');\n",
    "            const classSet = new Set();\n",
    "            for (const el of allElements) {\n",
    "                for (const cls of el.classList) {\n",
    "                    if (cls.match(/attach|file|linked|item|doc|single|detail|panel/i)) {\n",
    "                        classSet.add(cls);\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            debug.relevantClasses = Array.from(classSet).slice(0, 25);\n",
    "            \n",
    "            // Check for Angular scope on singleLinkedItem\n",
    "            const items = document.querySelectorAll('.singleLinkedItem');\n",
    "            if (items.length > 0) {\n",
    "                try {\n",
    "                    const scope = angular.element(items[0]).scope();\n",
    "                    debug.scopeKeys = scope ? Object.keys(scope).filter(k => !k.startsWith('$')).slice(0, 10) : [];\n",
    "                    if (scope?.attachment) {\n",
    "                        debug.attachmentKeys = Object.keys(scope.attachment);\n",
    "                    }\n",
    "                } catch(e) {\n",
    "                    debug.scopeError = e.message;\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return debug;\n",
    "        }\n",
    "    ''')\n",
    "    \n",
    "    # Check in main page (outside iframe)\n",
    "    page_debug = await page.evaluate('''\n",
    "        () => {\n",
    "            const debug = {\n",
    "                location: 'main_page',\n",
    "                singleLinkedItems: document.querySelectorAll('.singleLinkedItem').length,\n",
    "                ngRepeatAttachment: document.querySelectorAll('[ng-repeat*=\"attachment\"]').length,\n",
    "            };\n",
    "            \n",
    "            return debug;\n",
    "        }\n",
    "    ''')\n",
    "    \n",
    "    return {\n",
    "        'iframe': frame_debug,\n",
    "        'main_page': page_debug\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import tempfile\n",
    "\n",
    "async def download_files_batch(\n",
    "    frame: Frame, \n",
    "    file_ids: list[str], \n",
    "    page: Page,\n",
    "    downloads_dir: Path,\n",
    "    batch_num: int = 0,\n",
    "    timeout_ms: int = 120000  # 2 minutes per batch\n",
    ") -> tuple[bool, list[dict]]:\n",
    "    \"\"\"\n",
    "    Trigger download for a batch of files, unzip, and extract individual files.\n",
    "    \n",
    "    Uses Playwright's expect_download() to verify the download actually happens.\n",
    "    Automatically unzips and extracts files to the downloads directory.\n",
    "    \n",
    "    Args:\n",
    "        frame: The content frame\n",
    "        file_ids: List of file IDs to download\n",
    "        page: Playwright page object\n",
    "        downloads_dir: Directory to save extracted files\n",
    "        batch_num: Batch number for logging\n",
    "        timeout_ms: Max time to wait for download\n",
    "    \n",
    "    Returns (success: bool, extracted_files: list[dict] with file info or error message)\n",
    "    \"\"\"\n",
    "    if not file_ids:\n",
    "        return True, []\n",
    "    \n",
    "    try:\n",
    "        # Use expect_download to capture the actual download\n",
    "        async with page.expect_download(timeout=timeout_ms) as download_info:\n",
    "            # Trigger the download\n",
    "            await frame.evaluate('''\n",
    "                (ids) => DMSSystem.InitiateSelectedFilesRequest([], ids, [])\n",
    "            ''', file_ids)\n",
    "        \n",
    "        # Get the download object\n",
    "        download = await download_info.value\n",
    "        \n",
    "        # Save to a temp file first\n",
    "        with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as tmp:\n",
    "            tmp_path = Path(tmp.name)\n",
    "        \n",
    "        await download.save_as(tmp_path)\n",
    "        \n",
    "        # Verify file exists and has content\n",
    "        if not tmp_path.exists() or tmp_path.stat().st_size == 0:\n",
    "            tmp_path.unlink(missing_ok=True)\n",
    "            return False, \"Downloaded file is empty or missing\"\n",
    "        \n",
    "        # Extract files from zip\n",
    "        extracted_files = []\n",
    "        try:\n",
    "            with zipfile.ZipFile(tmp_path, 'r') as zf:\n",
    "                for zip_info in zf.infolist():\n",
    "                    if zip_info.is_dir():\n",
    "                        continue\n",
    "                    \n",
    "                    # Get just the filename (ignore any directory structure in zip)\n",
    "                    original_name = Path(zip_info.filename).name\n",
    "                    \n",
    "                    # Handle duplicate filenames by adding suffix\n",
    "                    dest_path = downloads_dir / original_name\n",
    "                    counter = 1\n",
    "                    while dest_path.exists():\n",
    "                        stem = Path(original_name).stem\n",
    "                        suffix = Path(original_name).suffix\n",
    "                        dest_path = downloads_dir / f\"{stem}_{counter}{suffix}\"\n",
    "                        counter += 1\n",
    "                    \n",
    "                    # Extract file\n",
    "                    with zf.open(zip_info) as src, open(dest_path, 'wb') as dst:\n",
    "                        dst.write(src.read())\n",
    "                    \n",
    "                    extracted_files.append({\n",
    "                        'original_name': original_name,\n",
    "                        'saved_as': dest_path.name,\n",
    "                        'size': zip_info.file_size,\n",
    "                        'batch': batch_num\n",
    "                    })\n",
    "        finally:\n",
    "            # Clean up temp zip file\n",
    "            tmp_path.unlink(missing_ok=True)\n",
    "        \n",
    "        return True, extracted_files\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if \"Timeout\" in error_msg:\n",
    "            return False, \"Timeout waiting for download\"\n",
    "        return False, f\"Error: {error_msg[:100]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Main Workflow Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def collect_attachments_incremental(\n",
    "    frame: Frame, \n",
    "    page: Page,\n",
    "    submittals: list[dict],\n",
    "    manifest: Manifest,\n",
    "    progress_interval: int = 50,\n",
    "    save_interval: int = 100,\n",
    "    verbose: bool = False\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Scan submittals for attachments, skipping already-processed ones.\n",
    "    Uses Playwright's native click to properly trigger Angular events.\n",
    "    \"\"\"\n",
    "    new_processed = 0\n",
    "    total_attachments_this_run = 0\n",
    "    \n",
    "    for i, sub in enumerate(submittals):\n",
    "        submittal_id = sub['submittalregid']\n",
    "        submittal_number = sub.get('number', str(submittal_id))\n",
    "        \n",
    "        if manifest.is_submittal_processed(submittal_id):\n",
    "            continue\n",
    "        \n",
    "        if new_processed % progress_interval == 0:\n",
    "            print(f\"Progress: {new_processed}/{len(submittals) - len(manifest.processed_submittals)} | \"\n",
    "                  f\"Attachments found: {total_attachments_this_run}\")\n",
    "        \n",
    "        # Find row index in current data\n",
    "        row_index = await frame.evaluate('''\n",
    "            (sid) => $(\"#ugDataView\").data(\"igGrid\").dataSource.data().findIndex(r => r.submittalregid === sid)\n",
    "        ''', submittal_id)\n",
    "        \n",
    "        if row_index < 0:\n",
    "            if verbose:\n",
    "                print(f\"  [{submittal_number}] Row not found in grid, skipping\")\n",
    "            continue\n",
    "        \n",
    "        # Scroll to row\n",
    "        await scroll_to_row(frame, row_index)\n",
    "        await page.wait_for_timeout(200)\n",
    "        \n",
    "        # Click row using Playwright's native click (triggers Angular properly)\n",
    "        if not await click_row_and_wait_for_sidebar(page, submittal_id):\n",
    "            if verbose:\n",
    "                print(f\"  [{submittal_number}] Failed to click row\")\n",
    "            continue\n",
    "        \n",
    "        # Extract attachments\n",
    "        attachments = await extract_attachments(frame, submittal_id, submittal_number)\n",
    "        \n",
    "        if verbose or (new_processed < 5):  # Always show first 5 for debugging\n",
    "            print(f\"  [{submittal_number}] Found {len(attachments)} attachments\")\n",
    "        \n",
    "        for att in attachments:\n",
    "            manifest.add_attachment(att)\n",
    "            total_attachments_this_run += 1\n",
    "        \n",
    "        manifest.mark_submittal_processed(submittal_id)\n",
    "        new_processed += 1\n",
    "        \n",
    "        if new_processed % save_interval == 0:\n",
    "            manifest.save(config.manifest_path)\n",
    "    \n",
    "    manifest.save(config.manifest_path)\n",
    "    print(f\"\\nDone! Processed {new_processed} new submittals\")\n",
    "    print(f\"Total attachments found this run: {total_attachments_this_run}\")\n",
    "    \n",
    "    return new_processed\n",
    "\n",
    "\n",
    "def save_submittals_csv(submittals: list[dict], path: Path) -> None:\n",
    "    \"\"\"Save submittals data to CSV.\"\"\"\n",
    "    df = pd.DataFrame(submittals)\n",
    "    \n",
    "    priority_cols = [\n",
    "        'submittalregid', 'number', 'subject', 'specsection', \n",
    "        'workflowstatename', 'responsiblecompanyname', 'authorcompanyname',\n",
    "        'datecreated', 'datedue', 'lastmodified'\n",
    "    ]\n",
    "    other_cols = [c for c in df.columns if c not in priority_cols]\n",
    "    df = df[[c for c in priority_cols if c in df.columns] + other_cols]\n",
    "    \n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Saved {len(df)} submittals to {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run the Extraction\n",
    "\n",
    "### Step 1: Launch Browser & Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved session...\n",
      "Already authenticated!\n",
      "Browser ready!\n"
     ]
    }
   ],
   "source": [
    "# Launch browser and login\n",
    "pw, browser, context, page = await launch_browser(headless=False)\n",
    "await login_if_needed(page, context)\n",
    "\n",
    "# Get content frame\n",
    "frame = await get_content_frame(page)\n",
    "print(\"Browser ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Apply Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying filter: 05 12 00 - Structural Steel\n",
      "Expanded division 05\n",
      "Selected: 05 12 00 - Structural Steel\n",
      "Switched to list view\n",
      "\n",
      "Filtered results: 276 submittals\n"
     ]
    }
   ],
   "source": [
    "await page.wait_for_timeout(10000)\n",
    "\n",
    "# Apply the spec section filter\n",
    "await apply_spec_section_filter(page, frame, config.spec_section_filter)\n",
    "\n",
    "# Verify filter was applied\n",
    "count = await get_current_filter_count(frame)\n",
    "print(f\"\\nFiltered results: {count} submittals\")\n",
    "\n",
    "# Update manifest with filter info\n",
    "manifest.filter_applied = config.spec_section_filter\n",
    "manifest.save(config.manifest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Extract Submittal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total submittals (filtered): 276\n",
      "Fields available: ['submittalregid', 'is_selected', 'number', 'revision', 'specsection', 'specsubsection', 'subject', 'workflowstatename', 'datedue', 'openassignmentscontactnames', 'datecreated', 'dateresolved', 'authorcompanyname', 'authorcontactname', 'resolutioncompanyname', 'resolutioncontactname', 'responsiblecompanyname', 'location', 'type', 'importance', 'submittalpackage', 'startdate', 'actualdate', 'returneddate', 'scheduleddeliverydate', 'actualdeliverydate', 'workflowtemplatename', 'workflowstepname', 'stepduedate', 'lastmodifiedby', 'lastmodified', 'locationid', 'specsectionid', 'workflowstate', 'authorcompanyid', 'authorcontactid', 'responsiblecompanyid', 'typeid', 'importanceid', 'submittalpackageid', 'details', 'resolution', 'workflowstatecolor', 'islocked', 'guid', 'projectid', 'openassignmentscompanynames', 'udf_submissionref', 'udf_drawingpackagenum', 'udf_scopeofwork', 'udf_scopeofwork_displayvalue', 'udf_purposeofsubmission', 'udf_purposeofsubmission_displayvalue', 'udf_secaioriginator', 'udf_secaiteamlead', 'udf_contractor_vendorapproval', 'udf_jacobssamooapproval', 'more']\n",
      "Saved 276 submittals to /mnt/c/Users/pdcur/OneDrive - MXI/Samsung - Samsung/Dashboard/Data/raw/projectsight/submittals/05_12_00/submittals.csv\n"
     ]
    }
   ],
   "source": [
    "# Get filtered submittal data\n",
    "submittals = await get_all_submittals_full(frame)\n",
    "print(f\"Total submittals (filtered): {len(submittals)}\")\n",
    "print(f\"Fields available: {list(submittals[0].keys()) if submittals else 'N/A'}\")\n",
    "\n",
    "# Save to CSV\n",
    "save_submittals_csv(submittals, config.submittals_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Scan for Attachments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Processed 0 new submittals\n",
      "Total attachments found this run: 0\n",
      "\n",
      "Summary:\n",
      "  Filter: 05 12 00 - Structural Steel\n",
      "  Total submittals processed: 276\n",
      "  Total attachments found: 947\n",
      "  Pending downloads: 947\n"
     ]
    }
   ],
   "source": [
    "# Scan for attachments (incremental - skips already processed)\n",
    "new_count = await collect_attachments_incremental(\n",
    "    frame, \n",
    "    page, \n",
    "    submittals,\n",
    "    manifest,\n",
    "    progress_interval=50,\n",
    "    save_interval=100\n",
    ")\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Filter: {manifest.filter_applied}\")\n",
    "print(f\"  Total submittals processed: {len(manifest.processed_submittals)}\")\n",
    "print(f\"  Total attachments found: {len(manifest.attachments)}\")\n",
    "print(f\"  Pending downloads: {len(manifest.get_pending_downloads())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Review Before Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to reset downloads if needed\n",
    "# manifest.reset_downloads()\n",
    "# manifest.save(config.manifest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review pending downloads\n",
    "pending = manifest.get_pending_downloads()\n",
    "print(f\"Pending downloads: {len(pending)}\")\n",
    "\n",
    "# Show sample\n",
    "for att in pending[:5]:\n",
    "    print(f\"  [{att['submittal_number']}] {att['file_name']} ({att['file_size']:,} bytes)\")\n",
    "\n",
    "# Total size estimate\n",
    "total_bytes = sum(att['file_size'] for att in pending)\n",
    "print(f\"\\nTotal size: {total_bytes / 1024 / 1024:.2f} MB ({total_bytes / 1024 / 1024 / 1024:.2f} GB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export attachments with submittal linkage\n",
    "attachments_df = pd.DataFrame(manifest.attachments)\n",
    "print(f\"Columns: {list(attachments_df.columns)}\")\n",
    "print(f\"\\nSample data:\")\n",
    "attachments_df[['submittal_number', 'file_name', 'file_id', 'field_label']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save attachments linkage to CSV\n",
    "attachments_path = config.output_dir / 'attachments.csv'\n",
    "attachments_df.to_csv(attachments_path, index=False)\n",
    "print(f\"Saved {len(attachments_df)} attachments to {attachments_path}\")\n",
    "\n",
    "# Show summary by submittal\n",
    "print(f\"\\nAttachments per submittal:\")\n",
    "print(attachments_df.groupby('submittal_number').size().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files in small batches, unzip and extract individual files\n",
    "BATCH_SIZE = 10  # Files per batch\n",
    "\n",
    "pending = manifest.get_pending_downloads()\n",
    "total_batches = (len(pending) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "print(f\"Downloading {len(pending)} files in {total_batches} batches of {BATCH_SIZE}...\")\n",
    "print(f\"Files will be extracted to: {config.downloads_dir}\\n\")\n",
    "\n",
    "successful_batches = 0\n",
    "total_extracted = 0\n",
    "failed_batches = []\n",
    "\n",
    "for batch_num in range(total_batches):\n",
    "    start_idx = batch_num * BATCH_SIZE\n",
    "    batch = pending[start_idx:start_idx + BATCH_SIZE]\n",
    "    \n",
    "    file_ids = [att['file_id'] for att in batch]\n",
    "    \n",
    "    print(f\"Batch {batch_num + 1}/{total_batches}: {len(file_ids)} files...\", end=\" \")\n",
    "    \n",
    "    success, result = await download_files_batch(\n",
    "        frame, file_ids, page, \n",
    "        downloads_dir=config.downloads_dir,\n",
    "        batch_num=batch_num + 1,\n",
    "        timeout_ms=180000  # 3 minutes per batch\n",
    "    )\n",
    "    \n",
    "    if success:\n",
    "        extracted_files = result\n",
    "        total_extracted += len(extracted_files)\n",
    "        \n",
    "        # Mark each file as downloaded with extraction info\n",
    "        for att, extracted in zip(batch, extracted_files):\n",
    "            manifest.mark_file_downloaded(att['file_id'], {\n",
    "                'file_name': att['file_name'],\n",
    "                'file_size': att['file_size'],\n",
    "                'submittal_id': att['submittal_id'],\n",
    "                'saved_as': extracted['saved_as'],\n",
    "                'batch': batch_num + 1\n",
    "            })\n",
    "        \n",
    "        manifest.save(config.manifest_path)\n",
    "        successful_batches += 1\n",
    "        print(f\" Extracted {len(extracted_files)} files\")\n",
    "    else:\n",
    "        failed_batches.append({\n",
    "            'batch': batch_num + 1,\n",
    "            'file_ids': file_ids,\n",
    "            'error': result\n",
    "        })\n",
    "        print(f\" {result}\")\n",
    "    \n",
    "    # Small delay between batches\n",
    "    await page.wait_for_timeout(2000)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Download Summary:\")\n",
    "print(f\"  Successful batches: {successful_batches}/{total_batches}\")\n",
    "print(f\"  Total files extracted: {total_extracted}\")\n",
    "print(f\"  Files marked downloaded: {len(manifest.downloaded_files)}\")\n",
    "print(f\"  Remaining: {len(manifest.get_pending_downloads())}\")\n",
    "if failed_batches:\n",
    "    print(f\"\\nFailed batches ({len(failed_batches)}):\")\n",
    "    for fb in failed_batches[:5]:\n",
    "        print(f\"  Batch {fb['batch']}: {fb['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Export Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export attachments manifest to CSV\n",
    "attachments_df = pd.DataFrame(manifest.attachments)\n",
    "attachments_path = config.output_dir / 'attachments.csv'\n",
    "attachments_df.to_csv(attachments_path, index=False)\n",
    "print(f\"Saved {len(attachments_df)} attachments to {attachments_path}\")\n",
    "\n",
    "# Show summary by field type\n",
    "if 'field_label' in attachments_df.columns:\n",
    "    print(\"\\nAttachments by type:\")\n",
    "    print(attachments_df['field_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close browser\n",
    "await browser.close()\n",
    "await pw.stop()\n",
    "print(\"Browser closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset downloads only (keeps submittals and attachments)\n",
    "# Uncomment to use:\n",
    "# manifest.reset_downloads()\n",
    "# manifest.save(config.manifest_path)\n",
    "# print(f\"Pending downloads: {len(manifest.get_pending_downloads())}\")\n",
    "\n",
    "# DANGER: Reset FULL manifest (uncomment to use)\n",
    "# if config.manifest_path.exists():\n",
    "#     config.manifest_path.unlink()\n",
    "#     print(\"Manifest deleted\")\n",
    "#     manifest = Manifest()\n",
    "#     print(\"Fresh manifest created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Reference\n",
    "\n",
    "### Changing the Filter\n",
    "Edit `spec_section_filter` in the Config class:\n",
    "```python\n",
    "spec_section_filter: str = '05 12 00 - Structural Steel'\n",
    "# Other examples:\n",
    "# '03 30 00 - Cast-in-Place Concrete'\n",
    "# '23 00 00 - HVAC'\n",
    "# '26 00 00 - Electrical'\n",
    "```\n",
    "\n",
    "### Output Structure\n",
    "```\n",
    "raw/projectsight/submittals/\n",
    " 05_12_00/                    # Filter-specific folder\n",
    "     submittals.csv           # Full submittal data\n",
    "     attachments.csv          # All discovered files\n",
    "     manifest.json            # Progress tracking\n",
    "     files/                   # Extracted files (auto-unzipped)\n",
    "         drawing_001.pdf\n",
    "         drawing_001_1.pdf    # Duplicate renamed\n",
    "         spec_sheet.pdf\n",
    "```\n",
    "\n",
    "### Manifest Structure\n",
    "```json\n",
    "{\n",
    "  \"filter_applied\": \"05 12 00 - Structural Steel\",\n",
    "  \"processed_submittals\": [567, 568, ...],\n",
    "  \"downloaded_files\": {\n",
    "    \"file_id_123\": {\n",
    "      \"file_name\": \"original.pdf\",\n",
    "      \"saved_as\": \"original.pdf\",\n",
    "      \"batch\": 1,\n",
    "      \"downloaded_at\": \"2024-01-15T10:30:00\"\n",
    "    }\n",
    "  },\n",
    "  \"attachments\": [...],\n",
    "  \"last_updated\": \"2024-01-15T10:30:00\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Resetting Downloads\n",
    "To re-download all files without re-scanning submittals:\n",
    "```python\n",
    "manifest.reset_downloads()\n",
    "manifest.save(config.manifest_path)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
