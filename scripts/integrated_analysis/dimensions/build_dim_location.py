#!/usr/bin/env python3
"""
Build dim_location.csv from location_master.csv

Generates the location dimension table from the taxonomy-derived location master,
adding building-wide and site-wide entries to capture all task locations.
Includes in_drawings flag computed by extracting codes from PDF floor drawings.
Infers grid coordinates for rooms missing bounds by matching room numbers across floors.

Source: raw/location_mappings/location_master.csv (generated by generate_location_master.py)
Output: processed/integrated_analysis/dimensions/dim_location.csv

Usage:
    python scripts/integrated_analysis/dimensions/build_dim_location.py
    python scripts/integrated_analysis/dimensions/build_dim_location.py --dry-run
    python scripts/integrated_analysis/dimensions/build_dim_location.py --rebuild  # Rebuild in_drawings only
    python scripts/integrated_analysis/dimensions/build_dim_location.py --preserve-extra
"""

import argparse
import re
import sys
from pathlib import Path

import pandas as pd

# Add project root to path
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from src.config.settings import Settings


# ============================================================================
# Drawing Extraction Functions
# ============================================================================

def extract_codes_from_drawings() -> dict:
    """Extract location codes from all PDF floor drawings.

    Returns dict with:
        - 'rooms': set of room codes (FAB1XXXXX)
        - 'elevators': set of elevator codes (FAB1-ELXX)
        - 'stairs': set of stair codes (FAB1-STXX)
    """
    try:
        import fitz  # PyMuPDF
    except ImportError:
        print("WARNING: PyMuPDF not installed. in_drawings will be None.")
        print("         Install with: pip install pymupdf")
        return None

    drawings_dir = Settings.RAW_DATA_DIR / 'drawings'
    if not drawings_dir.exists():
        print(f"WARNING: Drawings directory not found: {drawings_dir}")
        return None

    pdf_files = sorted(drawings_dir.glob('*.pdf'))
    if not pdf_files:
        print(f"WARNING: No PDF files found in {drawings_dir}")
        return None

    print(f"\nExtracting codes from {len(pdf_files)} PDF drawings...")

    all_rooms = set()
    all_elevators = set()
    all_stairs = set()

    for pdf_path in pdf_files:
        doc = fitz.open(pdf_path)
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()

        # Extract room codes (FAB1 + 5 digits)
        rooms = set(re.findall(r'FAB1\d{5}', text, re.IGNORECASE))
        all_rooms.update({c.upper() for c in rooms})

        # Extract elevator codes (FAB1-EL + number/letter)
        elevators = set(re.findall(r'FAB1-EL\d+[A-Z]?', text, re.IGNORECASE))
        all_elevators.update({c.upper() for c in elevators})

        # Extract stair codes (FAB1-ST + number)
        stairs = set(re.findall(r'FAB1-ST\d+', text, re.IGNORECASE))
        all_stairs.update({c.upper() for c in stairs})

    print(f"  Extracted: {len(all_rooms)} rooms, {len(all_elevators)} elevators, {len(all_stairs)} stairs")

    return {
        'rooms': all_rooms,
        'elevators': all_elevators,
        'stairs': all_stairs
    }


def get_drawing_code(location_type: str, location_code: str, drawing_codes: dict | None) -> str | None:
    """Convert P6 location code to drawing code if it exists in drawings.

    Args:
        location_type: Type of location (STAIR, ELEVATOR, etc.)
        location_code: The P6 location code (e.g., STR-01, ELV-05)
        drawing_codes: Dict from extract_codes_from_drawings() or None

    Returns:
        Drawing code (FAB1-STXX, FAB1-ELXX) if exists, None otherwise
    """
    if drawing_codes is None:
        return None

    code_upper = str(location_code).upper()

    # Convert STAIR (STR-XX -> FAB1-STXX)
    if location_type == 'STAIR':
        match = re.match(r'STR-(\d+)$', code_upper)
        if match:
            num = match.group(1).zfill(2)
            fab_code = f'FAB1-ST{num}'
            # Check if this FAB code exists in drawings
            if fab_code in drawing_codes['stairs']:
                return fab_code
        return None

    # Convert ELEVATOR (ELV-XX -> FAB1-ELXX)
    if location_type == 'ELEVATOR':
        match = re.match(r'ELV-(\d+)([A-Z])?$', code_upper)
        if match:
            num = match.group(1).zfill(2)
            suffix = match.group(2) or ''
            fab_code = f'FAB1-EL{num}{suffix}'
            # Check if this FAB code exists in drawings
            if fab_code in drawing_codes['elevators']:
                return fab_code
        return None

    return None


def compute_in_drawings(location_type: str, location_code: str, drawing_codes: dict | None) -> bool | None:
    """Determine if a location is found in the PDF drawings.

    Args:
        location_type: Type of location (ROOM, ELEVATOR, STAIR, etc.)
        location_code: The location code (e.g., FAB112345, ELV-01, FAB1-ST01)
        drawing_codes: Dict from extract_codes_from_drawings() or None

    Returns:
        True if found in drawings, False if not found, None if drawings unavailable
    """
    if drawing_codes is None:
        return None

    # Aggregate types are always "in drawings" conceptually
    if location_type in ['LEVEL', 'BUILDING', 'AREA', 'GRIDLINE', 'SITE', 'UNDEFINED']:
        return True

    code_upper = str(location_code).upper()

    # Check ROOM
    if location_type == 'ROOM':
        return code_upper in drawing_codes['rooms']

    # Check ELEVATOR - handles both P6 format (ELV-XX) and drawing format (FAB1-ELXX)
    if location_type == 'ELEVATOR':
        # Direct match for drawing codes
        if code_upper in drawing_codes['elevators']:
            return True
        # P6 format (ELV-XX -> FAB1-ELXX)
        match = re.match(r'ELV-(\d+)([A-Z])?$', code_upper)
        if match:
            num = match.group(1).zfill(2)
            suffix = match.group(2) or ''
            fab_code = f'FAB1-EL{num}{suffix}'
            return fab_code in drawing_codes['elevators']
        return False

    # Check STAIR - handles both P6 format (STR-XX) and drawing format (FAB1-STXX)
    if location_type == 'STAIR':
        # Direct match for drawing codes
        if code_upper in drawing_codes['stairs']:
            return True
        # P6 format (STR-XX -> FAB1-STXX)
        match = re.match(r'STR-(\d+)$', code_upper)
        if match:
            num = match.group(1).zfill(2)
            fab_code = f'FAB1-ST{num}'
            return fab_code in drawing_codes['stairs']
        return False

    return None


# ============================================================================
# Grid Inference Functions
# ============================================================================

def parse_fab_room_code(code: str) -> tuple[str, str] | tuple[None, None]:
    """Parse FAB1XXXXX room code into (floor_area, room_num).

    FAB codes have structure: FAB1[FLOOR_AREA][ROOM_NUM]
    - floor_area: single digit encoding building+level (1=SUW-1F, 2=SUW-2F, etc.)
    - room_num: 4-digit room number (same room on different floors shares this)

    Args:
        code: Room code like FAB136406

    Returns:
        Tuple of (floor_area, room_num) or (None, None) if not a valid FAB code
    """
    if not isinstance(code, str):
        return None, None
    match = re.match(r'FAB1(\d)(\d{4})$', code.upper())
    if match:
        return match.group(1), match.group(2)
    return None, None


def infer_grid_from_sibling_rooms(location_master: pd.DataFrame) -> dict[str, dict]:
    """Build lookup of inferred grid bounds from sibling rooms on other floors.

    Same room_num on different floors (e.g., FAB126406 and FAB136406) represents
    the same room type at the same grid location. If one has grid bounds and
    the other doesn't, we can infer the bounds.

    Args:
        location_master: DataFrame from location_master.csv

    Returns:
        Dict mapping location_code -> inferred grid bounds and source code
    """
    rooms = location_master[location_master['Location_Type'] == 'ROOM'].copy()

    # Build room_num -> list of rooms with grid bounds
    grid_by_room_num: dict[str, list[dict]] = {}
    for _, row in rooms[rooms['Row_Min'].notna()].iterrows():
        _, room_num = parse_fab_room_code(row['Code'])
        if room_num:
            if room_num not in grid_by_room_num:
                grid_by_room_num[room_num] = []
            grid_by_room_num[room_num].append({
                'code': row['Code'],
                'row_min': row['Row_Min'],
                'row_max': row['Row_Max'],
                'col_min': row['Col_Min'],
                'col_max': row['Col_Max'],
            })

    # Find rooms missing grid that have matching room_num elsewhere
    inferred = {}
    for _, row in rooms[rooms['Row_Min'].isna()].iterrows():
        code = row['Code']
        _, room_num = parse_fab_room_code(code)
        if room_num and room_num in grid_by_room_num:
            source = grid_by_room_num[room_num][0]  # Take first match
            inferred[code] = {
                'row_min': source['row_min'],
                'row_max': source['row_max'],
                'col_min': source['col_min'],
                'col_max': source['col_max'],
                'source_code': source['code'],
            }

    return inferred


# ============================================================================
# Manual Location Fixes
# ============================================================================
# Some locations in P6 have incorrect metadata or missing grid bounds that
# cannot be automatically inferred. These fixes are applied after loading
# location_master but before building dim_location.
#
# Each fix documents the investigation findings for traceability.

MANUAL_LOCATION_FIXES = {
    # -------------------------------------------------------------------------
    # ELV-24: Elevator not in drawings, incorrectly assigned to SUW
    # -------------------------------------------------------------------------
    # Investigation (2026-01-24):
    #
    # PROBLEM: ELV-24 was assigned to SUW-1F with no grid bounds.
    #          FAB1-EL24 does NOT exist in the floor drawings.
    #
    # EVIDENCE FROM P6 TASK NAMES:
    #   - "PH1- INSTALL ELEVATOR STEEL - SEB-5- ELEVATOR 24 - L1 GL 31-32 B-C"
    #   - "FRAMING & DRYWALL - ELEVATOR 24 - SEA5 - GL 31-33 - L1 - C-A"
    #   - "ELEVATOR SUPPORT STEEL - ELEVATOR 24 - SEB5 - GL 33"
    #
    # KEY FINDINGS:
    #   - Building: SEB-5, SEA5 = Support EAST Building (SUE), not SUW
    #   - Grid columns: 31-33
    #   - Grid rows: B-C (from "GL 31-32 B-C" and "C-A" references)
    #   - Levels: 1F, 2F, 3F (MULTI)
    #
    # RELATIONSHIP WITH EL18:
    #   - UDF data contains "ELEVATOR 18/24" references, indicating paired elevators
    #   - FAB1-EL18: SUE, rows B-D, cols 30-32
    #   - ELV-24:    SUE, rows B-C, cols 31-33 (offset by 1 column)
    #   - These are adjacent elevator shafts in the same bank
    #
    # CONCLUSION: ELV-24 is a real elevator in SUE building adjacent to EL18,
    #             but it has no drawing code (FAB1-EL24 not in architectural drawings).
    #             Grid bounds extracted from P6 task names.
    #
    'ELV-24': {
        'building': 'SUE',           # Changed from SUW (was incorrect)
        'level': 'MULTI',            # Spans 1F-3F per task names
        'grid_row_min': 'B',
        'grid_row_max': 'C',
        'grid_col_min': 31,
        'grid_col_max': 33,
        'status': 'EXTRACTED',       # Grid extracted from P6 task names
        'room_name': 'ELEVATOR 24',  # Add descriptive name
        # Note: in_drawings will be False (FAB1-EL24 doesn't exist)
    },
}


def apply_manual_fixes(location_master: pd.DataFrame) -> pd.DataFrame:
    """Apply manual fixes to location_master before building dim_location.

    Args:
        location_master: DataFrame from location_master.csv

    Returns:
        DataFrame with manual fixes applied
    """
    df = location_master.copy()
    fixes_applied = 0

    for code, fixes in MANUAL_LOCATION_FIXES.items():
        mask = df['Code'] == code
        if mask.any():
            for field, value in fixes.items():
                # Map our fix field names to location_master column names
                col_map = {
                    'building': 'Building',
                    'level': 'Level',
                    'grid_row_min': 'Row_Min',
                    'grid_row_max': 'Row_Max',
                    'grid_col_min': 'Col_Min',
                    'grid_col_max': 'Col_Max',
                    'status': 'Action_Status',
                    'room_name': 'Room_Name',
                }
                if field in col_map:
                    col = col_map[field]
                    old_val = df.loc[mask, col].iloc[0] if col in df.columns else None
                    df.loc[mask, col] = value
                    print(f"  {code}: {col} = {old_val} -> {value}")
            fixes_applied += 1

    if fixes_applied > 0:
        print(f"Applied manual fixes to {fixes_applied} locations")

    return df


# ============================================================================
# Static Entries
# ============================================================================

# Building-wide entries to add (for tasks with building but no level)
BUILDING_WIDE_ENTRIES = [
    {'location_code': 'SUP-ALL', 'location_type': 'BUILDING', 'building': 'SUP', 'level': 'ALL', 'room_name': 'SUP Building-Wide'},
    {'location_code': 'FAB-ALL', 'location_type': 'BUILDING', 'building': 'FAB', 'level': 'ALL', 'room_name': 'FAB Building-Wide'},
    {'location_code': 'SUW-ALL', 'location_type': 'BUILDING', 'building': 'SUW', 'level': 'ALL', 'room_name': 'SUW Building-Wide'},
    {'location_code': 'SUE-ALL', 'location_type': 'BUILDING', 'building': 'SUE', 'level': 'ALL', 'room_name': 'SUE Building-Wide'},
    {'location_code': 'FIZ-ALL', 'location_type': 'BUILDING', 'building': 'FIZ', 'level': 'ALL', 'room_name': 'FIZ Building-Wide'},
    {'location_code': 'OB1-ALL', 'location_type': 'BUILDING', 'building': 'OB1', 'level': 'ALL', 'room_name': 'OB1 Building-Wide'},
    {'location_code': 'GCS-ALL', 'location_type': 'BUILDING', 'building': 'GCS', 'level': 'ALL', 'room_name': 'GCS Building-Wide'},
]

# Site-wide entry (for tasks with no building or level)
SITE_ENTRY = {
    'location_code': 'SITE',
    'location_type': 'SITE',
    'building': None,
    'level': None,
    'room_name': 'Site-Wide',
}

# Undefined entry (for activities that are not building-wide but can't determine location)
UNDEFINED_ENTRY = {
    'location_code': 'UNDEFINED',
    'location_type': 'UNDEFINED',
    'building': None,
    'level': None,
    'room_name': 'Undefined Location',
}

# MULTI-level gridline entries (for grid-based matching when no room coverage exists)
# These span all rows (A-N) for each column and work across all floor levels
MULTI_GRIDLINE_COLUMNS = list(range(1, 34))  # Columns 1-33


def load_location_master() -> pd.DataFrame:
    """Load location_master.csv from raw data."""
    master_path = Settings.RAW_DATA_DIR / 'location_mappings' / 'location_master.csv'
    if not master_path.exists():
        raise FileNotFoundError(f"location_master.csv not found at {master_path}")

    df = pd.read_csv(master_path)
    print(f"Loaded location_master.csv: {len(df)} rows")
    return df


def load_existing_dim_location() -> pd.DataFrame:
    """Load existing dim_location.csv if it exists."""
    dim_path = Settings.PROCESSED_DATA_DIR / 'integrated_analysis' / 'dimensions' / 'dim_location.csv'
    if dim_path.exists():
        return pd.read_csv(dim_path)
    return None


def build_dim_location(location_master: pd.DataFrame, drawing_codes: dict | None = None,
                       preserve_extra: bool = False,
                       inferred_grids: dict | None = None) -> pd.DataFrame:
    """
    Build dim_location from location_master.

    Args:
        location_master: DataFrame from location_master.csv
        drawing_codes: Dict from extract_codes_from_drawings() for computing in_drawings
        preserve_extra: If True, preserve entries from existing dim_location that aren't in location_master
        inferred_grids: Dict from infer_grid_from_sibling_rooms() for rooms missing bounds

    Returns:
        DataFrame with dim_location structure
    """
    rows = []
    location_id = 1
    inferred_count = 0

    # Process each row from location_master
    for _, row in location_master.iterrows():
        loc_type = row['Location_Type']
        p6_code = row['Code']  # Original P6 code (STR-XX, ELV-XX, etc.)

        # Convert to drawing code if available (STR-01 -> FAB1-ST01)
        drawing_code = get_drawing_code(loc_type, p6_code, drawing_codes)
        loc_code = drawing_code if drawing_code else p6_code

        # Check if we have grid bounds from location_master
        has_grid = pd.notna(row['Row_Min'])
        grid_inferred_from = None

        # Try to infer grid if missing and we have inferred_grids lookup
        if not has_grid and inferred_grids and p6_code in inferred_grids:
            inferred = inferred_grids[p6_code]
            grid_row_min = inferred['row_min']
            grid_row_max = inferred['row_max']
            grid_col_min = inferred['col_min']
            grid_col_max = inferred['col_max']
            grid_inferred_from = inferred['source_code']
            inferred_count += 1
        else:
            grid_row_min = row['Row_Min'] if pd.notna(row['Row_Min']) else None
            grid_row_max = row['Row_Max'] if pd.notna(row['Row_Max']) else None
            grid_col_min = row['Col_Min'] if pd.notna(row['Col_Min']) else None
            grid_col_max = row['Col_Max'] if pd.notna(row['Col_Max']) else None

        entry = {
            'location_id': location_id,
            'location_code': loc_code,
            'p6_alias': p6_code if drawing_code else None,  # Only set alias if we converted
            'location_type': loc_type,
            'room_name': row['Room_Name'] if pd.notna(row['Room_Name']) else None,
            'building': row['Building'] if pd.notna(row['Building']) else None,
            'level': row['Level'] if pd.notna(row['Level']) else None,
            'grid_row_min': grid_row_min,
            'grid_row_max': grid_row_max,
            'grid_col_min': grid_col_min,
            'grid_col_max': grid_col_max,
            'grid_inferred_from': grid_inferred_from,
            'status': row['Action_Status'],
            'task_count': row['Task_Count'] if pd.notna(row['Task_Count']) else 0,
            'in_drawings': compute_in_drawings(loc_type, loc_code, drawing_codes),
        }

        # Build building_level key
        # For LEVEL type, building is NULL so just use level
        # For others, combine building-level if both present
        if loc_type == 'LEVEL':
            entry['building_level'] = row['Level'] if pd.notna(row['Level']) else None
        elif pd.notna(row['Building']) and pd.notna(row['Level']):
            entry['building_level'] = f"{row['Building']}-{row['Level']}"
        else:
            entry['building_level'] = None

        rows.append(entry)
        location_id += 1

    if inferred_count > 0:
        print(f"\nInferred grid bounds for {inferred_count} rooms from sibling rooms")

    # Add building-wide entries
    print(f"\nAdding {len(BUILDING_WIDE_ENTRIES)} building-wide entries...")
    for bw_entry in BUILDING_WIDE_ENTRIES:
        entry = {
            'location_id': location_id,
            'location_code': bw_entry['location_code'],
            'p6_alias': None,
            'location_type': bw_entry['location_type'],
            'room_name': bw_entry['room_name'],
            'building': bw_entry['building'],
            'level': bw_entry['level'],
            'grid_row_min': None,
            'grid_row_max': None,
            'grid_col_min': None,
            'grid_col_max': None,
            'grid_inferred_from': None,
            'status': 'BUILDING_WIDE',
            'task_count': 0,
            'building_level': f"{bw_entry['building']}-ALL",
            'in_drawings': True,
        }
        rows.append(entry)
        location_id += 1
        print(f"  + {bw_entry['location_code']}")

    # Add site-wide entry
    print(f"\nAdding site-wide entry...")
    entry = {
        'location_id': location_id,
        'location_code': SITE_ENTRY['location_code'],
        'p6_alias': None,
        'location_type': SITE_ENTRY['location_type'],
        'room_name': SITE_ENTRY['room_name'],
        'building': SITE_ENTRY['building'],
        'level': SITE_ENTRY['level'],
        'grid_row_min': None,
        'grid_row_max': None,
        'grid_col_min': None,
        'grid_col_max': None,
        'grid_inferred_from': None,
        'status': 'SITE_WIDE',
        'task_count': 0,
        'building_level': 'SITE',
        'in_drawings': True,
    }
    rows.append(entry)
    location_id += 1
    print(f"  + SITE")

    # Add undefined entry
    print(f"\nAdding undefined entry...")
    entry = {
        'location_id': location_id,
        'location_code': UNDEFINED_ENTRY['location_code'],
        'p6_alias': None,
        'location_type': UNDEFINED_ENTRY['location_type'],
        'room_name': UNDEFINED_ENTRY['room_name'],
        'building': UNDEFINED_ENTRY['building'],
        'level': UNDEFINED_ENTRY['level'],
        'grid_row_min': None,
        'grid_row_max': None,
        'grid_col_min': None,
        'grid_col_max': None,
        'grid_inferred_from': None,
        'status': 'UNDEFINED',
        'task_count': 0,
        'building_level': 'UNDEFINED',
        'in_drawings': True,
    }
    rows.append(entry)
    location_id += 1
    print(f"  + UNDEFINED")

    # Add MULTI-level gridlines for columns that don't already have them
    # These provide fallback location matching for grid coordinates without room coverage
    existing_gridline_codes = {r['location_code'] for r in rows if r['location_type'] == 'GRIDLINE' and r['level'] == 'MULTI'}
    new_gridlines = 0
    for col in MULTI_GRIDLINE_COLUMNS:
        gridline_code = str(col)
        if gridline_code not in existing_gridline_codes:
            entry = {
                'location_id': location_id,
                'location_code': gridline_code,
                'p6_alias': None,
                'location_type': 'GRIDLINE',
                'room_name': f'Gridline {col}',
                'building': None,
                'level': 'MULTI',
                'grid_row_min': 'A',
                'grid_row_max': 'N',
                'grid_col_min': float(col),
                'grid_col_max': float(col),
                'grid_inferred_from': None,
                'status': 'GENERATED',
                'task_count': 0,
                'building_level': None,
                'in_drawings': True,  # Gridlines are always "in drawings" conceptually
            }
            rows.append(entry)
            location_id += 1
            new_gridlines += 1

    if new_gridlines > 0:
        print(f"\nAdded {new_gridlines} MULTI-level gridlines (columns 1-33)")

    # Preserve extra entries from existing dim_location if requested
    if preserve_extra:
        existing = load_existing_dim_location()
        if existing is not None:
            existing_codes = set(existing['location_code'].astype(str))
            new_codes = {r['location_code'] for r in rows}
            extra_codes = existing_codes - new_codes

            if extra_codes:
                print(f"\nPreserving {len(extra_codes)} extra entries from existing dim_location...")
                extra_rows = existing[existing['location_code'].astype(str).isin(extra_codes)]
                for _, erow in extra_rows.iterrows():
                    loc_type = erow['location_type']
                    loc_code = erow['location_code']
                    # Get p6_alias from existing if available
                    p6_alias = erow.get('p6_alias') if 'p6_alias' in erow.index and pd.notna(erow.get('p6_alias')) else None
                    # Get grid_inferred_from from existing if available
                    grid_inferred = erow.get('grid_inferred_from') if 'grid_inferred_from' in erow.index and pd.notna(erow.get('grid_inferred_from')) else None
                    entry = {
                        'location_id': location_id,
                        'location_code': loc_code,
                        'p6_alias': p6_alias,
                        'location_type': loc_type,
                        'room_name': erow['room_name'] if pd.notna(erow['room_name']) else None,
                        'building': erow['building'] if pd.notna(erow['building']) else None,
                        'level': erow['level'] if pd.notna(erow['level']) else None,
                        'grid_row_min': erow['grid_row_min'] if pd.notna(erow['grid_row_min']) else None,
                        'grid_row_max': erow['grid_row_max'] if pd.notna(erow['grid_row_max']) else None,
                        'grid_col_min': erow['grid_col_min'] if pd.notna(erow['grid_col_min']) else None,
                        'grid_col_max': erow['grid_col_max'] if pd.notna(erow['grid_col_max']) else None,
                        'grid_inferred_from': grid_inferred,
                        'status': erow['status'] if pd.notna(erow['status']) else 'PRESERVED',
                        'task_count': erow['task_count'] if pd.notna(erow['task_count']) else 0,
                        'building_level': erow['building_level'] if pd.notna(erow['building_level']) else None,
                        'in_drawings': compute_in_drawings(loc_type, loc_code, drawing_codes),
                    }
                    rows.append(entry)
                    location_id += 1
                print(f"  Preserved: {sorted(extra_codes)[:10]}{'...' if len(extra_codes) > 10 else ''}")

    df = pd.DataFrame(rows)

    # Ensure proper column order
    columns = [
        'location_id', 'location_code', 'p6_alias', 'location_type', 'room_name',
        'building', 'level', 'grid_row_min', 'grid_row_max',
        'grid_col_min', 'grid_col_max', 'grid_inferred_from', 'status', 'task_count', 'building_level',
        'in_drawings'
    ]
    df = df[columns]

    return df


def print_summary(df: pd.DataFrame):
    """Print summary of the generated dim_location."""
    print("\n" + "=" * 60)
    print("DIM_LOCATION SUMMARY")
    print("=" * 60)

    print(f"\nTotal entries: {len(df)}")
    print(f"Unique location_codes: {df['location_code'].nunique()}")

    # P6 alias conversions
    if 'p6_alias' in df.columns:
        converted = df['p6_alias'].notna().sum()
        if converted > 0:
            print(f"\n--- P6 Code Conversions ---")
            print(f"Codes converted to drawing codes: {converted}")
            for lt in ['STAIR', 'ELEVATOR']:
                subset = df[(df['location_type'] == lt) & df['p6_alias'].notna()]
                if len(subset) > 0:
                    print(f"  {lt}: {len(subset)} (e.g., {subset.iloc[0]['p6_alias']} -> {subset.iloc[0]['location_code']})")

    # Grid inference stats
    if 'grid_inferred_from' in df.columns:
        inferred_count = df['grid_inferred_from'].notna().sum()
        if inferred_count > 0:
            print(f"\n--- Grid Inference ---")
            print(f"Rooms with inferred grid bounds: {inferred_count}")
            inferred_df = df[df['grid_inferred_from'].notna()]
            for _, row in inferred_df.head(5).iterrows():
                print(f"  {row['location_code']} <- {row['grid_inferred_from']}")
            if inferred_count > 5:
                print(f"  ... and {inferred_count - 5} more")

    print("\nBy location_type:")
    for lt, count in df['location_type'].value_counts().items():
        print(f"  {lt}: {count}")

    print("\nBy status:")
    for status, count in df['status'].value_counts().items():
        print(f"  {status}: {count}")

    # Check building-wide and site entries
    bw_entries = df[df['status'] == 'BUILDING_WIDE']
    site_entries = df[df['status'] == 'SITE_WIDE']
    print(f"\nBuilding-wide entries: {len(bw_entries)}")
    print(f"Site-wide entries: {len(site_entries)}")

    # In drawings summary
    if 'in_drawings' in df.columns and df['in_drawings'].notna().any():
        print("\n--- Drawing Coverage ---")
        in_d = df['in_drawings'].sum()
        not_d = len(df) - in_d
        print(f"In drawings:     {in_d}")
        print(f"Not in drawings: {not_d}")

        # By location type
        print("\nBy location_type:")
        for lt in ['ROOM', 'ELEVATOR', 'STAIR']:
            subset = df[df['location_type'] == lt]
            if len(subset) > 0:
                in_count = subset['in_drawings'].sum()
                pct = 100 * in_count / len(subset) if len(subset) > 0 else 0
                print(f"  {lt}: {in_count}/{len(subset)} ({pct:.1f}%)")

        # Not in drawings by building
        not_in_df = df[df['in_drawings'] == False]
        if len(not_in_df) > 0:
            print("\nNot in drawings by building:")
            for bldg, count in not_in_df.groupby('building').size().sort_values(ascending=False).items():
                print(f"  {bldg}: {count}")


def rebuild_in_drawings(df: pd.DataFrame, drawing_codes: dict | None) -> pd.DataFrame:
    """Rebuild in_drawings column for an existing dim_location DataFrame."""
    df = df.copy()

    in_drawings_list = []
    for _, row in df.iterrows():
        loc_type = row['location_type']
        loc_code = row['location_code']
        in_drawings_list.append(compute_in_drawings(loc_type, loc_code, drawing_codes))

    df['in_drawings'] = in_drawings_list
    return df


def main():
    parser = argparse.ArgumentParser(
        description='Build dim_location.csv from location_master.csv or rebuild from existing'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Preview changes without writing file'
    )
    parser.add_argument(
        '--rebuild',
        action='store_true',
        help='Rebuild in_drawings for existing processed/dim_location.csv (preserves all entries)'
    )
    parser.add_argument(
        '--preserve-extra',
        action='store_true',
        help='Preserve extra entries from existing dim_location.csv'
    )
    parser.add_argument(
        '--skip-drawings',
        action='store_true',
        help='Skip PDF drawing extraction (in_drawings will be None)'
    )
    args = parser.parse_args()

    print("=" * 60)
    print("BUILD DIM_LOCATION")
    print("=" * 60)

    # Extract codes from PDF drawings (unless skipped)
    drawing_codes = None
    if not args.skip_drawings:
        drawing_codes = extract_codes_from_drawings()

    # Output always goes to processed/
    output_path = Settings.PROCESSED_DATA_DIR / 'integrated_analysis' / 'dimensions' / 'dim_location.csv'

    if args.rebuild:
        # Rebuild from existing processed dim_location (preserves rooms and other entries)
        if not output_path.exists():
            print(f"ERROR: dim_location not found: {output_path}")
            sys.exit(1)
        print(f"\nRebuilding from: {output_path}")
        existing = pd.read_csv(output_path)
        print(f"Loaded {len(existing)} entries")
        dim_location = rebuild_in_drawings(existing, drawing_codes)
    else:
        # Build from location_master.csv
        location_master = load_location_master()

        # Apply manual fixes for locations with known issues
        print("\nApplying manual location fixes...")
        location_master = apply_manual_fixes(location_master)

        # Infer grid bounds for rooms missing them from sibling rooms on other floors
        print("\nInferring grid bounds from sibling rooms...")
        inferred_grids = infer_grid_from_sibling_rooms(location_master)
        print(f"  Found {len(inferred_grids)} rooms that can inherit grid from other floors")

        dim_location = build_dim_location(
            location_master,
            drawing_codes=drawing_codes,
            preserve_extra=args.preserve_extra,
            inferred_grids=inferred_grids
        )

    # Print summary
    print_summary(dim_location)

    if args.dry_run:
        print(f"\n[DRY RUN] Would write {len(dim_location)} rows to:")
        print(f"  {output_path}")
        print("\nRun without --dry-run to apply changes.")
    else:
        # Ensure directory exists
        output_path.parent.mkdir(parents=True, exist_ok=True)
        dim_location.to_csv(output_path, index=False)
        print(f"\nWrote {len(dim_location)} rows to:")
        print(f"  {output_path}")


if __name__ == '__main__':
    main()
