#!/usr/bin/env python3
"""
Build dim_location.csv from location_master.csv

Generates the location dimension table from the taxonomy-derived location master,
adding building-wide and site-wide entries to capture all task locations.

Source: raw/location_mappings/location_master.csv (generated by generate_location_master.py)
Output: processed/integrated_analysis/dimensions/dim_location.csv

Usage:
    python scripts/integrated_analysis/dimensions/build_dim_location.py
    python scripts/integrated_analysis/dimensions/build_dim_location.py --dry-run
    python scripts/integrated_analysis/dimensions/build_dim_location.py --preserve-extra
"""

import argparse
import sys
from pathlib import Path

import pandas as pd

# Add project root to path
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from src.config.settings import Settings


# Building-wide entries to add (for tasks with building but no level)
BUILDING_WIDE_ENTRIES = [
    {'location_code': 'SUP-ALL', 'location_type': 'BUILDING', 'building': 'SUP', 'level': 'ALL', 'room_name': 'SUP Building-Wide'},
    {'location_code': 'FAB-ALL', 'location_type': 'BUILDING', 'building': 'FAB', 'level': 'ALL', 'room_name': 'FAB Building-Wide'},
    {'location_code': 'SUW-ALL', 'location_type': 'BUILDING', 'building': 'SUW', 'level': 'ALL', 'room_name': 'SUW Building-Wide'},
    {'location_code': 'SUE-ALL', 'location_type': 'BUILDING', 'building': 'SUE', 'level': 'ALL', 'room_name': 'SUE Building-Wide'},
    {'location_code': 'FIZ-ALL', 'location_type': 'BUILDING', 'building': 'FIZ', 'level': 'ALL', 'room_name': 'FIZ Building-Wide'},
    {'location_code': 'OB1-ALL', 'location_type': 'BUILDING', 'building': 'OB1', 'level': 'ALL', 'room_name': 'OB1 Building-Wide'},
    {'location_code': 'GCS-ALL', 'location_type': 'BUILDING', 'building': 'GCS', 'level': 'ALL', 'room_name': 'GCS Building-Wide'},
]

# Site-wide entry (for tasks with no building or level)
SITE_ENTRY = {
    'location_code': 'SITE',
    'location_type': 'SITE',
    'building': None,
    'level': None,
    'room_name': 'Site-Wide',
}


def load_location_master() -> pd.DataFrame:
    """Load location_master.csv from raw data."""
    master_path = Settings.RAW_DATA_DIR / 'location_mappings' / 'location_master.csv'
    if not master_path.exists():
        raise FileNotFoundError(f"location_master.csv not found at {master_path}")

    df = pd.read_csv(master_path)
    print(f"Loaded location_master.csv: {len(df)} rows")
    return df


def load_existing_dim_location() -> pd.DataFrame:
    """Load existing dim_location.csv if it exists."""
    dim_path = Settings.PROCESSED_DATA_DIR / 'integrated_analysis' / 'dimensions' / 'dim_location.csv'
    if dim_path.exists():
        return pd.read_csv(dim_path)
    return None


def build_dim_location(location_master: pd.DataFrame, preserve_extra: bool = False) -> pd.DataFrame:
    """
    Build dim_location from location_master.

    Args:
        location_master: DataFrame from location_master.csv
        preserve_extra: If True, preserve entries from existing dim_location that aren't in location_master

    Returns:
        DataFrame with dim_location structure
    """
    rows = []
    location_id = 1

    # Process each row from location_master
    for _, row in location_master.iterrows():
        entry = {
            'location_id': location_id,
            'location_code': row['Code'],
            'location_type': row['Location_Type'],
            'room_name': row['Room_Name'] if pd.notna(row['Room_Name']) else None,
            'building': row['Building'] if pd.notna(row['Building']) else None,
            'level': row['Level'] if pd.notna(row['Level']) else None,
            'grid_row_min': row['Row_Min'] if pd.notna(row['Row_Min']) else None,
            'grid_row_max': row['Row_Max'] if pd.notna(row['Row_Max']) else None,
            'grid_col_min': row['Col_Min'] if pd.notna(row['Col_Min']) else None,
            'grid_col_max': row['Col_Max'] if pd.notna(row['Col_Max']) else None,
            'status': row['Action_Status'],
            'task_count': row['Task_Count'] if pd.notna(row['Task_Count']) else 0,
        }

        # Build building_level key
        if pd.notna(row['Building']) and pd.notna(row['Level']):
            entry['building_level'] = f"{row['Building']}-{row['Level']}"
        else:
            entry['building_level'] = None

        rows.append(entry)
        location_id += 1

    # Add building-wide entries
    print(f"\nAdding {len(BUILDING_WIDE_ENTRIES)} building-wide entries...")
    for bw_entry in BUILDING_WIDE_ENTRIES:
        entry = {
            'location_id': location_id,
            'location_code': bw_entry['location_code'],
            'location_type': bw_entry['location_type'],
            'room_name': bw_entry['room_name'],
            'building': bw_entry['building'],
            'level': bw_entry['level'],
            'grid_row_min': None,
            'grid_row_max': None,
            'grid_col_min': None,
            'grid_col_max': None,
            'status': 'BUILDING_WIDE',
            'task_count': 0,
            'building_level': f"{bw_entry['building']}-ALL",
        }
        rows.append(entry)
        location_id += 1
        print(f"  + {bw_entry['location_code']}")

    # Add site-wide entry
    print(f"\nAdding site-wide entry...")
    entry = {
        'location_id': location_id,
        'location_code': SITE_ENTRY['location_code'],
        'location_type': SITE_ENTRY['location_type'],
        'room_name': SITE_ENTRY['room_name'],
        'building': SITE_ENTRY['building'],
        'level': SITE_ENTRY['level'],
        'grid_row_min': None,
        'grid_row_max': None,
        'grid_col_min': None,
        'grid_col_max': None,
        'status': 'SITE_WIDE',
        'task_count': 0,
        'building_level': 'SITE',
    }
    rows.append(entry)
    location_id += 1
    print(f"  + SITE")

    # Preserve extra entries from existing dim_location if requested
    if preserve_extra:
        existing = load_existing_dim_location()
        if existing is not None:
            existing_codes = set(existing['location_code'].astype(str))
            new_codes = {r['location_code'] for r in rows}
            extra_codes = existing_codes - new_codes

            if extra_codes:
                print(f"\nPreserving {len(extra_codes)} extra entries from existing dim_location...")
                extra_rows = existing[existing['location_code'].astype(str).isin(extra_codes)]
                for _, erow in extra_rows.iterrows():
                    entry = {
                        'location_id': location_id,
                        'location_code': erow['location_code'],
                        'location_type': erow['location_type'],
                        'room_name': erow['room_name'] if pd.notna(erow['room_name']) else None,
                        'building': erow['building'] if pd.notna(erow['building']) else None,
                        'level': erow['level'] if pd.notna(erow['level']) else None,
                        'grid_row_min': erow['grid_row_min'] if pd.notna(erow['grid_row_min']) else None,
                        'grid_row_max': erow['grid_row_max'] if pd.notna(erow['grid_row_max']) else None,
                        'grid_col_min': erow['grid_col_min'] if pd.notna(erow['grid_col_min']) else None,
                        'grid_col_max': erow['grid_col_max'] if pd.notna(erow['grid_col_max']) else None,
                        'status': erow['status'] if pd.notna(erow['status']) else 'PRESERVED',
                        'task_count': erow['task_count'] if pd.notna(erow['task_count']) else 0,
                        'building_level': erow['building_level'] if pd.notna(erow['building_level']) else None,
                    }
                    rows.append(entry)
                    location_id += 1
                print(f"  Preserved: {sorted(extra_codes)[:10]}{'...' if len(extra_codes) > 10 else ''}")

    df = pd.DataFrame(rows)

    # Ensure proper column order
    columns = [
        'location_id', 'location_code', 'location_type', 'room_name',
        'building', 'level', 'grid_row_min', 'grid_row_max',
        'grid_col_min', 'grid_col_max', 'status', 'task_count', 'building_level'
    ]
    df = df[columns]

    return df


def print_summary(df: pd.DataFrame):
    """Print summary of the generated dim_location."""
    print("\n" + "=" * 60)
    print("DIM_LOCATION SUMMARY")
    print("=" * 60)

    print(f"\nTotal entries: {len(df)}")
    print(f"Unique location_codes: {df['location_code'].nunique()}")

    print("\nBy location_type:")
    for lt, count in df['location_type'].value_counts().items():
        print(f"  {lt}: {count}")

    print("\nBy status:")
    for status, count in df['status'].value_counts().items():
        print(f"  {status}: {count}")

    # Check building-wide and site entries
    bw_entries = df[df['status'] == 'BUILDING_WIDE']
    site_entries = df[df['status'] == 'SITE_WIDE']
    print(f"\nBuilding-wide entries: {len(bw_entries)}")
    print(f"Site-wide entries: {len(site_entries)}")


def main():
    parser = argparse.ArgumentParser(
        description='Build dim_location.csv from location_master.csv'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Preview changes without writing file'
    )
    parser.add_argument(
        '--preserve-extra',
        action='store_true',
        help='Preserve extra entries from existing dim_location.csv'
    )
    args = parser.parse_args()

    print("=" * 60)
    print("BUILD DIM_LOCATION")
    print("=" * 60)

    # Load location_master
    location_master = load_location_master()

    # Build dim_location
    dim_location = build_dim_location(location_master, preserve_extra=args.preserve_extra)

    # Print summary
    print_summary(dim_location)

    # Save or show dry-run
    output_path = Settings.PROCESSED_DATA_DIR / 'integrated_analysis' / 'dimensions' / 'dim_location.csv'

    if args.dry_run:
        print(f"\n[DRY RUN] Would write {len(dim_location)} rows to:")
        print(f"  {output_path}")
        print("\nRun without --dry-run to apply changes.")
    else:
        # Ensure directory exists
        output_path.parent.mkdir(parents=True, exist_ok=True)
        dim_location.to_csv(output_path, index=False)
        print(f"\nWrote {len(dim_location)} rows to:")
        print(f"  {output_path}")


if __name__ == '__main__':
    main()
