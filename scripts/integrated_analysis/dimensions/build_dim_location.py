#!/usr/bin/env python3
"""
Build dim_location.csv from location_master.csv

Generates the location dimension table from the taxonomy-derived location master,
adding building-wide and site-wide entries to capture all task locations.
Includes in_drawings flag computed by extracting codes from PDF floor drawings.

Source: raw/location_mappings/location_master.csv (generated by generate_location_master.py)
Output: processed/integrated_analysis/dimensions/dim_location.csv

Usage:
    python scripts/integrated_analysis/dimensions/build_dim_location.py
    python scripts/integrated_analysis/dimensions/build_dim_location.py --dry-run
    python scripts/integrated_analysis/dimensions/build_dim_location.py --rebuild  # Rebuild in_drawings only
    python scripts/integrated_analysis/dimensions/build_dim_location.py --preserve-extra
"""

import argparse
import re
import sys
from pathlib import Path

import pandas as pd

# Add project root to path
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from src.config.settings import Settings


# ============================================================================
# Drawing Extraction Functions
# ============================================================================

def extract_codes_from_drawings() -> dict:
    """Extract location codes from all PDF floor drawings.

    Returns dict with:
        - 'rooms': set of room codes (FAB1XXXXX)
        - 'elevators': set of elevator codes (FAB1-ELXX)
        - 'stairs': set of stair codes (FAB1-STXX)
    """
    try:
        import fitz  # PyMuPDF
    except ImportError:
        print("WARNING: PyMuPDF not installed. in_drawings will be None.")
        print("         Install with: pip install pymupdf")
        return None

    drawings_dir = Settings.RAW_DATA_DIR / 'drawings'
    if not drawings_dir.exists():
        print(f"WARNING: Drawings directory not found: {drawings_dir}")
        return None

    pdf_files = sorted(drawings_dir.glob('*.pdf'))
    if not pdf_files:
        print(f"WARNING: No PDF files found in {drawings_dir}")
        return None

    print(f"\nExtracting codes from {len(pdf_files)} PDF drawings...")

    all_rooms = set()
    all_elevators = set()
    all_stairs = set()

    for pdf_path in pdf_files:
        doc = fitz.open(pdf_path)
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()

        # Extract room codes (FAB1 + 5 digits)
        rooms = set(re.findall(r'FAB1\d{5}', text, re.IGNORECASE))
        all_rooms.update({c.upper() for c in rooms})

        # Extract elevator codes (FAB1-EL + number/letter)
        elevators = set(re.findall(r'FAB1-EL\d+[A-Z]?', text, re.IGNORECASE))
        all_elevators.update({c.upper() for c in elevators})

        # Extract stair codes (FAB1-ST + number)
        stairs = set(re.findall(r'FAB1-ST\d+', text, re.IGNORECASE))
        all_stairs.update({c.upper() for c in stairs})

    print(f"  Extracted: {len(all_rooms)} rooms, {len(all_elevators)} elevators, {len(all_stairs)} stairs")

    return {
        'rooms': all_rooms,
        'elevators': all_elevators,
        'stairs': all_stairs
    }


def get_drawing_code(location_type: str, location_code: str, drawing_codes: dict | None) -> str | None:
    """Convert P6 location code to drawing code if it exists in drawings.

    Args:
        location_type: Type of location (STAIR, ELEVATOR, etc.)
        location_code: The P6 location code (e.g., STR-01, ELV-05)
        drawing_codes: Dict from extract_codes_from_drawings() or None

    Returns:
        Drawing code (FAB1-STXX, FAB1-ELXX) if exists, None otherwise
    """
    if drawing_codes is None:
        return None

    code_upper = str(location_code).upper()

    # Convert STAIR (STR-XX -> FAB1-STXX)
    if location_type == 'STAIR':
        match = re.match(r'STR-(\d+)$', code_upper)
        if match:
            num = match.group(1).zfill(2)
            fab_code = f'FAB1-ST{num}'
            # Check if this FAB code exists in drawings
            if fab_code in drawing_codes['stairs']:
                return fab_code
        return None

    # Convert ELEVATOR (ELV-XX -> FAB1-ELXX)
    if location_type == 'ELEVATOR':
        match = re.match(r'ELV-(\d+)([A-Z])?$', code_upper)
        if match:
            num = match.group(1).zfill(2)
            suffix = match.group(2) or ''
            fab_code = f'FAB1-EL{num}{suffix}'
            # Check if this FAB code exists in drawings
            if fab_code in drawing_codes['elevators']:
                return fab_code
        return None

    return None


def compute_in_drawings(location_type: str, location_code: str, drawing_codes: dict | None) -> bool | None:
    """Determine if a location is found in the PDF drawings.

    Args:
        location_type: Type of location (ROOM, ELEVATOR, STAIR, etc.)
        location_code: The location code (e.g., FAB112345, ELV-01, FAB1-ST01)
        drawing_codes: Dict from extract_codes_from_drawings() or None

    Returns:
        True if found in drawings, False if not found, None if drawings unavailable
    """
    if drawing_codes is None:
        return None

    # Aggregate types are always "in drawings" conceptually
    if location_type in ['LEVEL', 'BUILDING', 'AREA', 'GRIDLINE', 'SITE']:
        return True

    code_upper = str(location_code).upper()

    # Check ROOM
    if location_type == 'ROOM':
        return code_upper in drawing_codes['rooms']

    # Check ELEVATOR - handles both P6 format (ELV-XX) and drawing format (FAB1-ELXX)
    if location_type == 'ELEVATOR':
        # Direct match for drawing codes
        if code_upper in drawing_codes['elevators']:
            return True
        # P6 format (ELV-XX -> FAB1-ELXX)
        match = re.match(r'ELV-(\d+)([A-Z])?$', code_upper)
        if match:
            num = match.group(1).zfill(2)
            suffix = match.group(2) or ''
            fab_code = f'FAB1-EL{num}{suffix}'
            return fab_code in drawing_codes['elevators']
        return False

    # Check STAIR - handles both P6 format (STR-XX) and drawing format (FAB1-STXX)
    if location_type == 'STAIR':
        # Direct match for drawing codes
        if code_upper in drawing_codes['stairs']:
            return True
        # P6 format (STR-XX -> FAB1-STXX)
        match = re.match(r'STR-(\d+)$', code_upper)
        if match:
            num = match.group(1).zfill(2)
            fab_code = f'FAB1-ST{num}'
            return fab_code in drawing_codes['stairs']
        return False

    return None


# ============================================================================
# Static Entries
# ============================================================================

# Building-wide entries to add (for tasks with building but no level)
BUILDING_WIDE_ENTRIES = [
    {'location_code': 'SUP-ALL', 'location_type': 'BUILDING', 'building': 'SUP', 'level': 'ALL', 'room_name': 'SUP Building-Wide'},
    {'location_code': 'FAB-ALL', 'location_type': 'BUILDING', 'building': 'FAB', 'level': 'ALL', 'room_name': 'FAB Building-Wide'},
    {'location_code': 'SUW-ALL', 'location_type': 'BUILDING', 'building': 'SUW', 'level': 'ALL', 'room_name': 'SUW Building-Wide'},
    {'location_code': 'SUE-ALL', 'location_type': 'BUILDING', 'building': 'SUE', 'level': 'ALL', 'room_name': 'SUE Building-Wide'},
    {'location_code': 'FIZ-ALL', 'location_type': 'BUILDING', 'building': 'FIZ', 'level': 'ALL', 'room_name': 'FIZ Building-Wide'},
    {'location_code': 'OB1-ALL', 'location_type': 'BUILDING', 'building': 'OB1', 'level': 'ALL', 'room_name': 'OB1 Building-Wide'},
    {'location_code': 'GCS-ALL', 'location_type': 'BUILDING', 'building': 'GCS', 'level': 'ALL', 'room_name': 'GCS Building-Wide'},
]

# Site-wide entry (for tasks with no building or level)
SITE_ENTRY = {
    'location_code': 'SITE',
    'location_type': 'SITE',
    'building': None,
    'level': None,
    'room_name': 'Site-Wide',
}


def load_location_master() -> pd.DataFrame:
    """Load location_master.csv from raw data."""
    master_path = Settings.RAW_DATA_DIR / 'location_mappings' / 'location_master.csv'
    if not master_path.exists():
        raise FileNotFoundError(f"location_master.csv not found at {master_path}")

    df = pd.read_csv(master_path)
    print(f"Loaded location_master.csv: {len(df)} rows")
    return df


def load_existing_dim_location() -> pd.DataFrame:
    """Load existing dim_location.csv if it exists."""
    dim_path = Settings.PROCESSED_DATA_DIR / 'integrated_analysis' / 'dimensions' / 'dim_location.csv'
    if dim_path.exists():
        return pd.read_csv(dim_path)
    return None


def build_dim_location(location_master: pd.DataFrame, drawing_codes: dict | None = None,
                       preserve_extra: bool = False) -> pd.DataFrame:
    """
    Build dim_location from location_master.

    Args:
        location_master: DataFrame from location_master.csv
        drawing_codes: Dict from extract_codes_from_drawings() for computing in_drawings
        preserve_extra: If True, preserve entries from existing dim_location that aren't in location_master

    Returns:
        DataFrame with dim_location structure
    """
    rows = []
    location_id = 1

    # Process each row from location_master
    for _, row in location_master.iterrows():
        loc_type = row['Location_Type']
        p6_code = row['Code']  # Original P6 code (STR-XX, ELV-XX, etc.)

        # Convert to drawing code if available (STR-01 -> FAB1-ST01)
        drawing_code = get_drawing_code(loc_type, p6_code, drawing_codes)
        loc_code = drawing_code if drawing_code else p6_code

        entry = {
            'location_id': location_id,
            'location_code': loc_code,
            'p6_alias': p6_code if drawing_code else None,  # Only set alias if we converted
            'location_type': loc_type,
            'room_name': row['Room_Name'] if pd.notna(row['Room_Name']) else None,
            'building': row['Building'] if pd.notna(row['Building']) else None,
            'level': row['Level'] if pd.notna(row['Level']) else None,
            'grid_row_min': row['Row_Min'] if pd.notna(row['Row_Min']) else None,
            'grid_row_max': row['Row_Max'] if pd.notna(row['Row_Max']) else None,
            'grid_col_min': row['Col_Min'] if pd.notna(row['Col_Min']) else None,
            'grid_col_max': row['Col_Max'] if pd.notna(row['Col_Max']) else None,
            'status': row['Action_Status'],
            'task_count': row['Task_Count'] if pd.notna(row['Task_Count']) else 0,
            'in_drawings': compute_in_drawings(loc_type, loc_code, drawing_codes),
        }

        # Build building_level key
        if pd.notna(row['Building']) and pd.notna(row['Level']):
            entry['building_level'] = f"{row['Building']}-{row['Level']}"
        else:
            entry['building_level'] = None

        rows.append(entry)
        location_id += 1

    # Add building-wide entries
    print(f"\nAdding {len(BUILDING_WIDE_ENTRIES)} building-wide entries...")
    for bw_entry in BUILDING_WIDE_ENTRIES:
        entry = {
            'location_id': location_id,
            'location_code': bw_entry['location_code'],
            'p6_alias': None,
            'location_type': bw_entry['location_type'],
            'room_name': bw_entry['room_name'],
            'building': bw_entry['building'],
            'level': bw_entry['level'],
            'grid_row_min': None,
            'grid_row_max': None,
            'grid_col_min': None,
            'grid_col_max': None,
            'status': 'BUILDING_WIDE',
            'task_count': 0,
            'building_level': f"{bw_entry['building']}-ALL",
            'in_drawings': True,
        }
        rows.append(entry)
        location_id += 1
        print(f"  + {bw_entry['location_code']}")

    # Add site-wide entry
    print(f"\nAdding site-wide entry...")
    entry = {
        'location_id': location_id,
        'location_code': SITE_ENTRY['location_code'],
        'p6_alias': None,
        'location_type': SITE_ENTRY['location_type'],
        'room_name': SITE_ENTRY['room_name'],
        'building': SITE_ENTRY['building'],
        'level': SITE_ENTRY['level'],
        'grid_row_min': None,
        'grid_row_max': None,
        'grid_col_min': None,
        'grid_col_max': None,
        'status': 'SITE_WIDE',
        'task_count': 0,
        'building_level': 'SITE',
        'in_drawings': True,
    }
    rows.append(entry)
    location_id += 1
    print(f"  + SITE")

    # Preserve extra entries from existing dim_location if requested
    if preserve_extra:
        existing = load_existing_dim_location()
        if existing is not None:
            existing_codes = set(existing['location_code'].astype(str))
            new_codes = {r['location_code'] for r in rows}
            extra_codes = existing_codes - new_codes

            if extra_codes:
                print(f"\nPreserving {len(extra_codes)} extra entries from existing dim_location...")
                extra_rows = existing[existing['location_code'].astype(str).isin(extra_codes)]
                for _, erow in extra_rows.iterrows():
                    loc_type = erow['location_type']
                    loc_code = erow['location_code']
                    # Get p6_alias from existing if available
                    p6_alias = erow.get('p6_alias') if 'p6_alias' in erow.index and pd.notna(erow.get('p6_alias')) else None
                    entry = {
                        'location_id': location_id,
                        'location_code': loc_code,
                        'p6_alias': p6_alias,
                        'location_type': loc_type,
                        'room_name': erow['room_name'] if pd.notna(erow['room_name']) else None,
                        'building': erow['building'] if pd.notna(erow['building']) else None,
                        'level': erow['level'] if pd.notna(erow['level']) else None,
                        'grid_row_min': erow['grid_row_min'] if pd.notna(erow['grid_row_min']) else None,
                        'grid_row_max': erow['grid_row_max'] if pd.notna(erow['grid_row_max']) else None,
                        'grid_col_min': erow['grid_col_min'] if pd.notna(erow['grid_col_min']) else None,
                        'grid_col_max': erow['grid_col_max'] if pd.notna(erow['grid_col_max']) else None,
                        'status': erow['status'] if pd.notna(erow['status']) else 'PRESERVED',
                        'task_count': erow['task_count'] if pd.notna(erow['task_count']) else 0,
                        'building_level': erow['building_level'] if pd.notna(erow['building_level']) else None,
                        'in_drawings': compute_in_drawings(loc_type, loc_code, drawing_codes),
                    }
                    rows.append(entry)
                    location_id += 1
                print(f"  Preserved: {sorted(extra_codes)[:10]}{'...' if len(extra_codes) > 10 else ''}")

    df = pd.DataFrame(rows)

    # Ensure proper column order
    columns = [
        'location_id', 'location_code', 'p6_alias', 'location_type', 'room_name',
        'building', 'level', 'grid_row_min', 'grid_row_max',
        'grid_col_min', 'grid_col_max', 'status', 'task_count', 'building_level',
        'in_drawings'
    ]
    df = df[columns]

    return df


def print_summary(df: pd.DataFrame):
    """Print summary of the generated dim_location."""
    print("\n" + "=" * 60)
    print("DIM_LOCATION SUMMARY")
    print("=" * 60)

    print(f"\nTotal entries: {len(df)}")
    print(f"Unique location_codes: {df['location_code'].nunique()}")

    # P6 alias conversions
    if 'p6_alias' in df.columns:
        converted = df['p6_alias'].notna().sum()
        if converted > 0:
            print(f"\n--- P6 Code Conversions ---")
            print(f"Codes converted to drawing codes: {converted}")
            for lt in ['STAIR', 'ELEVATOR']:
                subset = df[(df['location_type'] == lt) & df['p6_alias'].notna()]
                if len(subset) > 0:
                    print(f"  {lt}: {len(subset)} (e.g., {subset.iloc[0]['p6_alias']} -> {subset.iloc[0]['location_code']})")

    print("\nBy location_type:")
    for lt, count in df['location_type'].value_counts().items():
        print(f"  {lt}: {count}")

    print("\nBy status:")
    for status, count in df['status'].value_counts().items():
        print(f"  {status}: {count}")

    # Check building-wide and site entries
    bw_entries = df[df['status'] == 'BUILDING_WIDE']
    site_entries = df[df['status'] == 'SITE_WIDE']
    print(f"\nBuilding-wide entries: {len(bw_entries)}")
    print(f"Site-wide entries: {len(site_entries)}")

    # In drawings summary
    if 'in_drawings' in df.columns and df['in_drawings'].notna().any():
        print("\n--- Drawing Coverage ---")
        in_d = df['in_drawings'].sum()
        not_d = len(df) - in_d
        print(f"In drawings:     {in_d}")
        print(f"Not in drawings: {not_d}")

        # By location type
        print("\nBy location_type:")
        for lt in ['ROOM', 'ELEVATOR', 'STAIR']:
            subset = df[df['location_type'] == lt]
            if len(subset) > 0:
                in_count = subset['in_drawings'].sum()
                pct = 100 * in_count / len(subset) if len(subset) > 0 else 0
                print(f"  {lt}: {in_count}/{len(subset)} ({pct:.1f}%)")

        # Not in drawings by building
        not_in_df = df[df['in_drawings'] == False]
        if len(not_in_df) > 0:
            print("\nNot in drawings by building:")
            for bldg, count in not_in_df.groupby('building').size().sort_values(ascending=False).items():
                print(f"  {bldg}: {count}")


def rebuild_in_drawings(df: pd.DataFrame, drawing_codes: dict | None) -> pd.DataFrame:
    """Rebuild in_drawings column for an existing dim_location DataFrame."""
    df = df.copy()

    in_drawings_list = []
    for _, row in df.iterrows():
        loc_type = row['location_type']
        loc_code = row['location_code']
        in_drawings_list.append(compute_in_drawings(loc_type, loc_code, drawing_codes))

    df['in_drawings'] = in_drawings_list
    return df


def main():
    parser = argparse.ArgumentParser(
        description='Build dim_location.csv from location_master.csv or rebuild from existing'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Preview changes without writing file'
    )
    parser.add_argument(
        '--rebuild',
        action='store_true',
        help='Rebuild in_drawings for existing processed/dim_location.csv (preserves all entries)'
    )
    parser.add_argument(
        '--preserve-extra',
        action='store_true',
        help='Preserve extra entries from existing dim_location.csv'
    )
    parser.add_argument(
        '--skip-drawings',
        action='store_true',
        help='Skip PDF drawing extraction (in_drawings will be None)'
    )
    args = parser.parse_args()

    print("=" * 60)
    print("BUILD DIM_LOCATION")
    print("=" * 60)

    # Extract codes from PDF drawings (unless skipped)
    drawing_codes = None
    if not args.skip_drawings:
        drawing_codes = extract_codes_from_drawings()

    # Output always goes to processed/
    output_path = Settings.PROCESSED_DATA_DIR / 'integrated_analysis' / 'dimensions' / 'dim_location.csv'

    if args.rebuild:
        # Rebuild from existing processed dim_location (preserves rooms and other entries)
        if not output_path.exists():
            print(f"ERROR: dim_location not found: {output_path}")
            sys.exit(1)
        print(f"\nRebuilding from: {output_path}")
        existing = pd.read_csv(output_path)
        print(f"Loaded {len(existing)} entries")
        dim_location = rebuild_in_drawings(existing, drawing_codes)
    else:
        # Build from location_master.csv
        location_master = load_location_master()
        dim_location = build_dim_location(
            location_master,
            drawing_codes=drawing_codes,
            preserve_extra=args.preserve_extra
        )

    # Print summary
    print_summary(dim_location)

    if args.dry_run:
        print(f"\n[DRY RUN] Would write {len(dim_location)} rows to:")
        print(f"  {output_path}")
        print("\nRun without --dry-run to apply changes.")
    else:
        # Ensure directory exists
        output_path.parent.mkdir(parents=True, exist_ok=True)
        dim_location.to_csv(output_path, index=False)
        print(f"\nWrote {len(dim_location)} rows to:")
        print(f"  {output_path}")


if __name__ == '__main__':
    main()
